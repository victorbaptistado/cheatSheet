<!DOCTYPE html>
<html>
    <header>
        <link href="/resources/css/index.css" type="text/css" rel="stylesheet" >
        <script src="../component/button.js" defer></script>
        <title>Database</title>
        <h1>Database</h1>
    </header>
    <body>
        <div class="styleGuide">
            <h2>Database</h2>
            <ul>
                <li><strong>Database</strong> is a set of data stored in a computer. This data is usually structured in 
                a way that makes the data easily accessible. <strong>DBMS</strong> is the specific software that allows 
                you to interact with a database.</li>
                <li><strong>Relational Database: </strong>
                A relational database is a type of database. It uses a structure that allows us to identify and access
                data in relation to another piece of data in the database. Often, data in a relational database is 
                organized into tables.</li>
                <ul>
                    <li><strong>Tables (Rows and Columns):</strong>
                    Tables can have hundreds, thousands, sometimes even millions of rows of data. These rows are often called 
                    records. Tables can also have many columns of data. Columns are labeled with a descriptive name 
                    (say, age for example) and have a specific data type.
                    For example, a column called age may have a type of INTEGER (denoting the type of data it is meant to hold).
                    In the table above, there are three columns (name, age, and country).
                    The name and country columns store string data types, whereas age stores integer data types. The set of 
                    columns and data types make up the schema of this table.
                    The table also has four rows, or records, in it (one each for Natalia, Ned, Zenas, and Laura).</li>
                </ul>
                <li><strong>NoSQL: </strong>
                Any database technology that stores data differently from relational.
                databases can be categorized as a NoSQL database.</li>
                <li><strong>Relational database VS NoSQL: </strong>Using a <strong>relational</strong> database structure, we might separate the information for each person, having 
                their id, name, and email, in one table named customers, and then another table for the subscriptions,
                having the newsletter name, and other information associated with the subscriptions.
                With a <strong>NoSQL database</strong>, instead of separating information in this way, 
                we might just have a single document with the person’s information, as well as the subscription 
                information, all in one document. Article about
                <a href="https://www.digitalocean.com/community/tutorials/a-comparison-of-nosql-database-management-systems-and-models" target="_blank">here</a>.</li>
            </ul>
        </div>
        <div class="styleGuide">
            <h2>SQL</h2>
            <ul>
                <h3>Relational Database Management System (RDBMS)</h3>
                <li><strong>Relational Database Management System (RDBMS):</strong>
                A relational database management system (RDBMS) is a program that allows you to create, update, and 
                administer a relational database. Most relational database management systems use the SQL language to 
                access the database. <strong>SQL (Structured Query Language)</strong> is a programming language used 
                to communicate with data stored in a relational database management system. SQL syntax is similar to 
                the English language, which makes it relatively easy to write, read, and interpret.
                Many RDBMSs use SQL (and variations of SQL) to access the data in tables. For example, SQLite is a 
                relational database management system. SQLite contains a minimal set of SQL commands (which are the 
                same across all RDBMSs). Other RDBMSs may use other variants.
                (SQL is often pronounced in one of two ways. You can pronounce it by speaking each letter individually 
                like “S-Q-L”, or pronounce it using the word “sequel”.)
                By learning the fundamentals with one RDBMS, you can easily begin work in another. Here are some popular RDBMSs:</li>
                <ul>               
                    <li><strong>MySQL:</strong> Is the most popular open source SQL database. It is typically used for web 
                    application development, and often accessed using PHP.
                    The main advantages of MySQL are that it is easy to use, inexpensive, reliable (has been around 
                    since 1995), and has a large community of developers who can help answer questions.                   
                    Some of the disadvantages are that it has been known to suffer from poor performance when scaling,
                    open source development has lagged since Oracle has taken control of MySQL, and it does not 
                    include some advanced features that developers may be used to.</li>
                    <li><strong>PostgreSQL</strong> Is an open source SQL database that is not controlled by any corporation. It is typically used for web application development.
                    PostgreSQL shares many of the same advantages of MySQL. It is easy to use, inexpensive, reliable and has a large community of developers. It also provides some additional features such as foreign key support without requiring complex configuration.                   
                    The main disadvantage of PostgreSQL is that it can be slower in performance than other databases such as MySQL. It is also slightly less popular than MySQL.
                    For more information about PostgreSQL including installation instructions, read this 
                    <a href="https://www.postgresql.org/" target="_blank">article</a>.</li>
                    <p class="center"><strong>Postgre Implementation:</strong></p>
                    <button id="showCode49" onclick="showCode('displayCode49', 'showCode49')">Display</button>
                    <div id="displayCode49">
                        <button onclick="closeCode('displayCode49', 'showCode49')">Close</button>
                        <li>In order to run and use Postgres on your own computer, you will need to <strong>set up both 
                        a Postgres server and a client.</strong></li>
                        <li><strong>Setting Up PostgreSQL (server): </strong>
                        Installation 
                        <a href="https://www.postgresql.org/download/windows/" target="_blank">here</a>.
                        You’ll be prompted to enter in a password for the postgres user: for now, set the password 
                        as “postgres”. If you are asked to enter a port, you can use the default of “5432”.
                        After completing the installation, you may be asked whether you would like to use Stack 
                        Builder to install additional software. You shouldn’t need to install anything else for now.</li>
                        <li><strong>Setting up PostgresSQL (client): </strong>
                        Now that Postgres is running locally, we can connect to it via a “client” – a graphical or 
                        command-line interface that enables us to connect to the Postgres server, write and execute 
                        SQL commands as input, and see the resulting output.
                        While you can have only one instance of Postgres running per port (typically 5432), you 
                        can have multiple open connections to the same database with different interfaces. 
                        There are many options; our preferences are listed below. <strong>Instructions and project 
                        to set-up Postgree Locally</strong>
                        <a href="https://content.codecademy.com/programs/data-engineering-postgres/Movies_Off_Platform_Project/Movies_Off_Platform_Project.zip" target="_blank">here</a>.</li>
                        <ul>
                            <li><strong>GUI: </strong>Our preference for a cross-platform software to visually 
                            interact with Postgres is <a href="https://github.com/Paxa/postbird" target="_blank">Postbird</a>.
                            A strong runner up is <u>PgAdmin</u>, one of the most popular and feature-rich open source 
                            administration and development platforms for Postgres.                        
                            Postbird will automatically open, and from there you can enter in the username (postgres) and password 
                            (postgres) to connect to your locally running Postgres instance.
                            From there you can now use Postbird to start writing SQL queries. You can select the database you want to 
                            work in using the dropdown menu in the top left corner, you can add tables to that database using the plus 
                            sign in the bottom left corner, and you can use the query tab to write SQL queries to manipulate and investigate
                            tables that you create!
                        </li>
                            <li><strong>Command Line: </strong>
                            You can also connect using the command line tool <a href="https://www.postgresql.org/docs/9.3/app-psql.html" target="_blank">psql</a>.</li>
                        </ul>
                        <hr/>
                    </div>
                    <li><strong>Oracle DB: </strong>Oracle Corporation owns Oracle Database, and the code is not open sourced.
                    Oracle DB is for large applications, particularly in the banking industry. Most of the world’s 
                    top banks run Oracle applications because Oracle offers a powerful combination of technology and 
                    comprehensive, pre-integrated business applications, including essential functionality built specifically for banks.                   
                    The main disadvantage of using Oracle is that it is not free to use like its open source 
                    competitors and can be quite expensive.</li>
                    <li><strong>SQL Server</strong>
                    Microsoft owns SQL Server. Like Oracle DB, the code is close sourced.                   
                    Large enterprise applications mostly use SQL Server.
                    Microsoft offers a free entry-level version called Express 
                    but can become very expensive as you scale your application.</li> 
                    <li><strong>SQLite</strong> is a popular open source SQL database. It can store an entire database 
                    in a single file. One of the most significant advantages this provides is that all of the data can be stored locally without having to connect your database to a server.
                    SQLite is a popular choice for databases in cellphones, PDAs, MP3 players, set-top boxes, and 
                    other electronic gadgets. The SQL courses on Codecademy use SQLite.                   
                    For more info on SQLite, including installation instructions, read this article.</li>
                </ul>
                <li>More info:</li>
                <ul>
                    <li><strong>Material</strong> <a href="https://www.codecademy.com/resources/docs/general/relational-database?page_ref=catalog" target="_blank">here</a>.</li>
                    <li><strong>Tool</strong> for easy online testing and sharing of database problems and their solutions 
                        <a href="http://sqlfiddle.com/" target="_blank">here</a>.
                    </li>
                    <li>
                        <strong>Guidelines</strong> for SQL use
                        <a href="https://gist.github.com/fredbenenson/7bb92718e19138c20591#file-kickstarter_sql_style_guide-md" target="_blank"> here</a>.
                    </li>
                </ul>
                <p class="center"><strong>Creating, Querying & Manipulating Tables:</strong></p>
                <button id="showCode47" onclick="showCode('displayCode47', 'showCode47')">Display</button>
                <div id="displayCode47">
                    <button onclick="closeCode('displayCode47', 'showCode47')">Close</button>
                    <li><strong>List of SQL Commands</strong> <a href="https://www.codecademy.com/article/sql-commands" target="_blank">here</a>.</li>
                    <hr/>
                    <li><strong>Creating Tables</strong></li>
                    <ul>
                        <li><strong>Creating Table Video Implementation</strong> <a href="https://www.youtube.com/watch?v=nwLV5Txc8jM&embeds_euri=https%3A%2F%2Fwww.codecademy.com%2F&embeds_origin=https%3A%2F%2Fwww.codecademy.com&source_ve_path=MjM4NTE&feature=emb_title" target="_blank">here</a>.</li>
                        <li><strong>Statements:</strong>
                        The code below is a SQL statement. A statement is text that the database recognizes as a 
                        valid command. Statements always end in a semicolon <i>;</i>.</li>
                        <pre>
                            <code>
                CREATE TABLE table_name (
                    column_1 data_type, 
                    column_2 data_type, 
                    column_3 data_type
                );

                //Example
                CREATE TABLE book (
                    title varchar(100),
                    isbn varchar(50) PRIMARY KEY,
                    pages integer,
                    price money,
                    description varchar(256),
                    publisher varchar(100)
                );

                //Create table from existing columns
                    (It's easier to create in first place) 
                CREATE TABLE majors AS
                SELECT distinct major_1, major_1_credits_reqd
                FROM college;

                //Then DROP the previous college columns
                    We just need a cross-reference 
                    between tables
                ALTER TABLE college
                DROP COLUMN major_1, 
                DROP COLUMN major_1_credits_reqd;
                            </code>
                        </pre>
                        <ol>
                            <li><strong>CREATE TABLE</strong> is a clause.  
                            Clauses perform specific tasks in SQL. By convention, clauses are 
                            written in capital letters. Clauses can also be referred to as commands.
                            CREATE TABLE tells SQL you want to create a new table.</li>
                            <li><strong>table_name</strong> refers to the name of the table that the command is 
                            applied to.</li>
                            <li><strong>(column_1 data_type, column_2 data_type, column_3 data_type)</strong> 
                            is a parameter. A parameter 
                            is a list of columns, data types, or values that are passed to a clause as an argument. 
                            Here, the parameter is a list of column names and the associated data type.</li>
                        </ol>
                    </ul>
                    <hr/>
                    <li><strong>Querying Tables</strong></li>
                    <ul>
                        <li><strong>Querying Table Video Implementation</strong> <a href="https://www.youtube.com/watch?v=gQ58W7v8qyA&ab_channel=Codecademy" target="_blank">here</a>.</li>
                        <li><strong>SELECT</strong> statements are used to fetch data from a database:</li>
                        <pre>
                            <code>
                SELECT name FROM celebs;

                //We can select individual columns by their names (separated by a comma):
                SELECT column1, column2 
                FROM table_name;

                //WHERE & LIKE
                SELECT * FROM movies
                WHERE name LIKE 'Se_en';

                //CASE & WHEN
                SELECT name,
                    CASE
                        WHEN imdb_rating > 8 THEN 'Fantastic'
                        WHEN imdb_rating > 6 THEN 'Poorly Received'
                        ELSE 'Avoid at All Costs'
                    END AS 'Review'
                FROM movies;

                SELECT name AS 'Titles'
                FROM movies;

                //Multiple aliases
                SELECT course_id AS "Course ID", exercise_id AS "Exercise ID" FROM bugs;

                SELECT tools FROM inventory;
                //might produce: tools, Hammer, Nails, Nails, Nails
                //By adding DISTINCT before the column name,
                SELECT DISTINCT tools FROM inventory;
                //the result would now be: tools, Hammer, Nails
                            </code>
                        </pre>
                        <ol>
                            <li><strong>SELECT</strong> is a clause that indicates that the statement is a query. You will use SELECT every 
                            time you query data from a database. SELECT statements always return a new table called the result set.</li>
                            <li>name specifies the column to query data from (we can use * to select every column in a table).</li>
                            <li><strong>FROM</strong> celebs specifies the name of the table to query data from. In this statement, data is 
                            queried from the celebs table.</li>
                            <li>You can add a WHERE clause to filter your results. For example, adding WHERE 
                            release_year = 1999 to the end of your SELECT statement will find all of the movies
                            released in 1999. We can combine multiple conditions in a WHERE clause 
                            to make the result set more specific and useful, one way of doing this is to use 
                            the <strong>AND</strong> & <STRONG>OR</STRONG>operator (we can combine both).
                            <strong>AND</strong> operator displays a row if all the conditions are true.
                            <strong>OR</strong> operator displays a row if any condition is true.</li>
                            <li><strong>LIKE</strong> is a special operator used with the WHERE clause to search for a specific 
                            pattern in a column. name LIKE 'Se_en' is a condition evaluating the name column for a specific pattern.
                            Se_en represents a pattern with a wildcard character.
                            The _ means you can substitute any individual character here without breaking the pattern.
                            <i>%</i> is a wildcard character that matches zero or more missing letters in the pattern. For example:
                            A% matches all movies with names that begin with letter ‘A’
                            %a matches all movies that end with ‘a’
                            We can also use % both before and after a pattern.</li>
                            <li><strong>BETWEEN</strong> sets a condition between two values.</li>
                            <li><strong>ORDER BY</strong> sorts the results either alphabetically or numerically.
                            <strong>DESC</strong> is a keyword used in ORDER BY to sort the results in descending order (high to low or Z-A).
                            <strong>ASC</strong> is a keyword used in ORDER BY to sort the results in ascending order (low to high or A-Z).</li>
                            <li>LIMIT is a clause that lets you specify the maximum number of rows the result set will have. This saves space on 
                            our screen and makes our queries run faster. LIMIT always goes at the very end of the query.</li>
                            <li>A <strong>CASE</strong> statement allows us to create different outputs (usually in the SELECT statement). 
                            It is SQL's way of handling if-then logic. 
                            Each <strong>WHEN</strong> tests a condition and the following THEN gives us the string if the condition is true.
                            The <strong>ELSE</strong> gives us the string if all the above conditions are false.
                            The CASE statement must end with <strong>END</strong>. To shorten it, we can rename the column to ‘Review’ using AS</li>
                            <li><strong>AS</strong> is a keyword in SQL that allows you to rename a column or table using an alias. The new 
                            name can be anything you want as long as you put it inside of single quotes.
                            When using AS, the columns are not being renamed in the table. The aliases only appear in the result.</li>
                            <li><strong>DISTINCT</strong> is used to return unique values in the output. It filters out 
                            all duplicate values in the specified column(s). For instance:</li>
                        </ol>         
                    </ul>
                    <hr/>
                    <li><strong>Manipulating Tables</strong></li>
                    <ul>
                        <li>The <strong>INSERT</strong> statement inserts a new row into a table.
                        (id, name, age) is a parameter identifying the columns that data will be inserted into.
                        <strong>VALUES</strong> is a clause that indicates the data being inserted.</li>
                        <pre>
                            <code>
                INSERT INTO celebs (id, name, age)
                VALUES (1, 'Justin Bieber', 22);

                //For multiple insertion
                INSERT INTO table (col1, col2, col3)
                VALUES
                (row1_val1, row1_val2, row1_val3),
                (row2_val1, row2_val2, row2_val3),
                (row3_val1, row3_val2, row3_val3);
                            </code>
                        </pre>
                        <ul>
                            <li><strong>INSERT INTO nested tables</strong>:
                                You can use a single SQL statement to insert the data into both the parent and child 
                                tables using the RETURNING clause to retrieve the generated ID. For example:</li>
                            <pre>
                                <code>
            WITH new_address AS (
                INSERT INTO addresses (street, city, state, country)
                VALUES ('123 Main St', 'Anytown', 'CA', 'USA')
                RETURNING id
                )
                INSERT INTO users (name, email, address_id)
                VALUES ('John Doe', 'jdoe@example.com', (SELECT id FROM new_address));          
                                </code>
                            </pre>
                        </ul>
                        <li>The <strong>ALTER TABLE:</strong> statement adds a new column to a table. You can use this command 
                        when you want to add columns to a table.
                        The ALTER statement is used to modify columns. With ALTER, you can add columns, remove them, 
                        or even modify them.</li>
                        <ul>
                            <pre>
                                <code>
                    //Add column
                    ALTER TABLE celebs 
                    ADD COLUMN twitter_handle TEXT;

                    //Rename column                
                    ALTER TABLE table_name
                    RENAME COLUMN old_name TO new_name;
                                </code>
                            </pre>
                            <li><strong>ADD COLUMN</strong> is a clause that lets you add a new column to a table:</li>
                            <ul>
                                <li>twitter_handle is the name of the new column being added</li>
                                <li>TEXT is the data type for the new column</li>
                            </ul>
                            <li>NULL is a special value in SQL that represents missing or unknown data. Here, the 
                            rows that existed before the column was added have NULL (∅) values for twitter_handle.</li>
                        </ul>
                        <li>The <strong>UPDATE</strong> statement edits a row in a table. You can use the UPDATE statement when you 
                        want to change existing records.
                        The UPDATE statement is used to modify rows. However, UPDATE can only update a row, and cannot 
                        remove or add rows.</li>
                        <ul>
                            <pre>
                                <code>
                UPDATE celebs 
                SET twitter_handle = '@taylorswift13' 
                WHERE id > 4; 
                                </code>
                            </pre>
                            <li>SET is a clause that indicates the column to edit.</li>
                            <ul>
                                <li>twitter_handle is the name of the column that is going to be updated</li>
                                <li>@taylorswift13 is the new value that is going to be inserted into the twitter_handle column.</li>
                            </ul>
                            <li><strong>WHERE</strong> is a clause that indicates which row(s) to update with the new 
                            column value. Here the row with a 4 in the id column is the row that will have the twitter_
                            handle updated to @taylorswift13.</li>
                        </ul>
                        <li>The <strong>DELETE FROM</strong> statement deletes one or more rows from a table. You can use the 
                        statement when you want to delete existing records. The statement below deletes all 
                        records in the celebs table with no twitter_handle:</li>
                        <ul>
                            <pre>
                                <code>
                DELETE FROM celebs 
                WHERE twitter_handle IS NULL;

                DELETE FROM employees
                WHERE employee_id IS NOT NULL;
                                </code>
                            </pre>
                            <li><strong>WHERE</strong> is a clause that lets you select which rows you want to delete. Here we want to delete all of the rows where the twitter_handle column IS NULL.</li>
                            <li><strong>IS NULL</strong> is a condition in SQL that returns true when the value is NULL and false otherwise.
                            There's also <strong> IS NOT NULL</strong> </li>
                        </ul>
                        <li><strong>Constraints</strong> that add information about how a column can be used are invoked 
                        after specifying the data type for a column. They can be used to tell the database to reject 
                        inserted data that does not adhere to a certain restriction. The statement below sets 
                        constraints on the celebs table.</li>
                        <pre>
                            <code>
                CREATE TABLE celebs (
                    id INTEGER PRIMARY KEY, 
                    name TEXT UNIQUE,
                    date_of_birth TEXT NOT NULL,
                    date_of_death TEXT DEFAULT 'Not Applicable'
                );

                // If we don't need a constraint, we can
                   use DROP in place of SET                
                ALTER TABLE talks
                ALTER COLUMN session_timeslot SET NOT NULL;
   
                //BACKFILL table, so error doesn't occur.            
                UPDATE talks
                SET title = 'TBD'
                WHERE title IS NULL;

                //CHECK
                ALTER TABLE talks 
                ADD CHECK (estimated_length > 0 AND estimated_length < 120);

                //another CHECK example              
                ALTER TABLE attendees 
                ADD CHECK (standard_tickets_reserved + vip_tickets_reserved = total_tickets_reserved);

                //Delete Cascade for referenced Foreign keys
                ALTER TABLE registrations
                ADD FOREIGN KEY (talk_id)
                REFERENCES talks (id) ON DELETE CASCADE

                            </code>
                        </pre>
                        <ul>
                            <li><strong>PRIMARY KEY</strong> columns can be used to uniquely identify the row. Attempts to insert a 
                            row with an identical value to a row already in the table will result in a constraint 
                            violation which will not allow you to insert the new row.</li>
                            <li><strong>UNIQUE</strong> columns have a different value for every row. This is similar to 
                            PRIMARY KEY except a table can have many different UNIQUE columns.</li>
                            <li><strong>NOT NULL</strong> columns must have a value. Attempts to insert a row without a value for a 
                            NOT NULL column will result in a constraint violation and the new row will not be inserted.</li>
                            <li><strong>CHECK</strong> statements can be used to implement more precise constraints on our table.
                            In some situations, we might want to establish specific rules to determine what makes a row valid.
                            A CHECK constraint can be written into a CREATE TABLE statement, or added to an existing table with 
                            ALTER TABLE.
                            As a general rule, any logic that you might use in a WHERE statement to filter 
                            individual rows from an existing table can be applied within a CHECK</li>
                            <li><strong>FOREIGN KEY</strong>
                            Values inserted into child table must be validated by data that’s already present in a parent table.
                            Formally, this property that ensures data can be validated by referencing another table in the data model 
                            is called referential integrity. Referential integrity can be enforced by adding a FOREIGN KEY on the child 
                            table that references the primary key of a parent table.
                            By default, a foreign key constraint will prevent an engineer from deleting or updating a row of a parent table 
                            that is referenced by some child table. This behavior is sometimes explicitly specified in a CREATE TABLE statement 
                            using REFERENCES talks (id) ON DELETE RESTRICT or REFERENCES talks (id) ON UPDATE RESTRICT.
                            Another way is using <strong>CASCADE</strong> clause.
                            Rather than preventing changes, CASCADE clauses (ON UPDATE CASCADE, ON DELETE CASCADE) cause 
                            the updates or deletes to automatically be applied to any child tables- once we right that statement,
                            we're able to delete normally.</li>
                            <li><strong>DEFAULT</strong> columns take an additional argument that will be the assumed value for an 
                            inserted row if the new row does not specify a value for that column.</li>
                            <li>We can use <strong>ALTER TABLE</strong> statements to add or remove constraints from existing 
                            tables. If the table we’re attempting to add a constraint on doesn’t meet the constraint, 
                            an error will occur, but we  can backfill the table so that it does adhere to the constraint.
                            <strong>Backfilling</strong> is a term
                            occasionally used in DB engineering to refer to the process of adding or updating past 
                            values. In this case, we can fill our target column’s NULL values with a placeholder 
                            value using the query below.</li>
                        </ul>
                        <li><strong>Information schema</strong> is a database containing meta information about 
                        objects in the database including tables, columns and constraints. This schema provides users 
                        with read-only views of many topics of interest.
                        To determine if a column has been designated correctly as a primary key, we can query a 
                        special view, key_column_usage, generated from this database. This view identifies all 
                        columns in the current database that are restricted by some constraint such as primary 
                        key or foreign key.</li>
                        <pre>
                            <code>
                //Only table_name needs to be
                   written based on the database
                SELECT
                    constraint_name, table_name, column_name
                FROM
                    information_schema.key_column_usage
                WHERE
                    table_name = 'recipe';
                            </code>
                        </pre>
                    </ul>
                    <li><strong>Auto-incrementing:</strong> Many times we need to automatically increment a 
                    column, for example an id, so we don't need to do it manually for each new insert.</li>
                    <pre>
                        <code>
            CREATE TABLE table_name(
                    id SERIAL
            );

            //Alter existing table to use auto-incrementing.
            // t = table, c = column                
            CREATE SEQUENCE "public"."t_c_seq" OWNED BY "public"."t"."c";
           
            ALTER TABLE "public"."t" ALTER COLUMN "c" SET DEFAULT nextval('"public"."t_c_seq"');
                        </code>
                    </pre>
                    <hr/>
                    <li><strong>Aggregates Functions</strong></li>
                    <ul>
                        <li><strong>Aggregating Functions Video Implementation I</strong> <a href="https://www.youtube.com/watch?v=-7fN2eWUTmI&ab_channel=Codecademy" target="_blank">here</a>.</li>
                        <li><strong>Aggregating Functions Video Implementation II</strong><a href="https://www.youtube.com/watch?v=CQA_c6nqLvw&ab_channel=Codecademy" target="_blank">here</a>.</li>   
                        <li>Calculations performed on multiple rows of a table are called aggregates.</li>
                        <ul>
                            <li><strong>COUNT():</strong> count the number of rows</li>
                            <pre>
                                <code>
                    SELECT COUNT(*)
                    FROM table_name;
                                </code>
                            </pre>
                            <li><strong>SUM():</strong> calculates the sum of the values in a column</li>
                            <pre>
                                <code>
                    SELECT SUM(downloads)
                    FROM fake_apps;
                                </code>
                            </pre>
                            <li><strong>MAX()/MIN():</strong> return the highest and lowest values in a column, respectively.</li>
                            <pre>
                                <code>
                    SELECT MAX(downloads)
                    FROM fake_apps;
                                </code>
                            </pre>
                            <li><strong>AVG():</strong> calculates  the average of the values in a column</li>
                            <pre>
                                <code>
                    SELECT AVG(downloads)
                    FROM fake_apps;
                                </code>
                            </pre>
                            <li><strong>ROUND():</strong> round the values in the column</li>
                            <pre>
                                <code>
                    SELECT ROUND(price, 0)
                    FROM fake_apps;
                                </code>
                            </pre>
                            <li><strong>GROUP BY: </strong>Oftentimes, we will want to calculate an aggregate for data with certain characteristics.
                            GROUP BY is a clause in SQL that is used with aggregate functions. It is used in collaboration with the SELECT 
                            statement to arrange identical data into groups.
                            Aggregate functions combine multiple rows together to form a single value of more meaningful information.
                            The GROUP BY statement comes after any WHERE statements, but before ORDER BY or LIMIT.</li>
                            <pre>
                                <code>
                    SELECT AVG(imdb_rating)
                    FROM movies
                    WHERE year = 1999;
                        
                    SELECT AVG(imdb_rating)
                    FROM movies
                    WHERE year = 2000;
                        
                    SELECT AVG(imdb_rating)
                    FROM movies
                    WHERE year = 2001;

                    //CAN BE WRITTEN AS
                    SELECT year,
                        AVG(imdb_rating)
                    FROM movies
                    GROUP BY year
                    ORDER BY year;
                                </code>
                            </pre>
                            <li>Sometimes, we want to <strong>GROUP BY</strong> a calculation done on a column.
                            SQL lets us use column reference(s) in our GROUP BY.</li>
                            <pre>
                                <code>
                    SELECT ROUND(imdb_rating), COUNT(name)
                    FROM movies
                    GROUP BY ROUND(imdb_rating)
                    ORDER BY ROUND(imdb_rating);
                    However, this query may be time-consuming to write and more prone to error.
                    
                    //The following query is equivalent to the one above
                    //The 1 refers to the first column in our 
                        SELECT statement, ROUND(imdb_rating).
                    SELECT ROUND(imdb_rating), COUNT(name)
                    FROM movies
                    GROUP BY 1
                    ORDER BY 1;

                    //1 refers to category, 2 refers to price
                    SELECT category, price,
                        AVG(downloads)
                    FROM fake_apps
                    GROUP BY 1, 2;
                                </code>
                            </pre>
                            <li><strong>HAVING: </strong>filters groups.
                            HAVING is very similar to WHERE. In fact, all types of WHERE clauses you learned about thus far can 
                            be used with HAVING.
                            <strong>WHERE</strong>When we want to limit the results of a query based on values of the individual rows.
                            <strong>HAVING</strong>When we want to limit the results of a query based on an aggregate property.</li>
                            <pre>
                                <code>
                SELECT year,
                    genre,
                    COUNT(name)
                FROM movies
                GROUP BY 1, 2
                HAVING COUNT(name) > 10;


                //GROUP BY & CASE
                SELECT CASE
                    WHEN url LIKE '%github.com%' THEN 'Github'
                    WHEN url LIKE '%medium.com%' THEN 'Medium'
                    WHEN url LIKE '%newyorktimes.com%' THEN 'New York Times'
                    ELSE 'NO URL'
                END AS 'SOURCE',
                COUNT(*) 
                FROM hacker_news
                GROUP BY 1;
                                </code>
                            </pre>
                            <li>SQLite Documentation about <strong>timestamps</strong> <a href='https://www.sqlite.org/lang_datefunc.html'>here</a></li>
                        </ul>
                    </ul>
                </div>
                <p class="center"><strong>Multiple Tables:</strong></p>
                <button id="showCode50" onclick="showCode('displayCode50', 'showCode50')">Display</button>
                <div id="displayCode50">
                    <button onclick="closeCode('displayCode50', 'showCode50')">Close</button>
                    <li><strong>Introduction</strong></li>
                    <ul>
                        <li>In order to efficiently store data, we often spread related information across <strong>multiple tables</strong>.
                        For instance, imagine that we’re running a magazine company where users can have different types 
                        of subscriptions to different products. Different subscriptions might have many different properties. 
                        Each customer would also have lots of associated information.
                        We could have one table with all of the following information:</li>
                        <ul>
                            <li>order_id</li>
                            <li>customer_id</li>
                            <li>customer_name</li>
                            <li>customer_address</li>
                            <li>subscription_id</li>
                            <li>subscription_description</li>
                            <li>subscription_monthly_price</li>
                            <li>subscription_length</li>
                            <li>purchase_date</li>
                        </ul>
                        <li>However, a lot of this information would be repeated. If the same customer has multiple subscriptions, that customer’s name and address will be reported multiple times. If the same subscription type is ordered by multiple customers, then the subscription price and subscription description will be repeated. This will make our table big and unmanageable.
                        So instead, we can split our data into three tables:</li>
                        <ol>
                            <li><strong>orders</strong> would contain just the information necessary to describe what was ordered:</li>
                            <ul>
                                <li>order_id, customer_id, subscription_id, purchase_date</li>
                            </ul>
                            <li><strong>subscriptions</strong> would contain the information to describe each type of subscription:
                            <ul>
                                <li>subscription_id, description, price_per_month, subscription_length</li>
                            </ul>
                            <li><strong>customers</strong> would contain the information for each customer:</li>
                            <ul>
                                <li>customer_id, customer_name, address</li>
                            </ul>
                        </ol>
                    </ul>
                    <li><strong>Database Normalization </strong>is a concept that most programmers use to refer 
                    to restructuring a database in this manner. It's so that databases tables are structured to 
                    avoid data redundancy and keep the data accurate and consistent.
                    More info <a href="https://www.1keydata.com/database-normalization/" target="_blank">here</a>.
                    Introduction to database normalization<a href="https://mikehillyer.com/articles/an-introduction-to-database-normalization/" target="_blank">here</a>.</li>
                    <ul>
                        <li>Say for example, we added 1 million rows to this table. Some values like customer_address
                        might end up being stored many thousands of times, when we really only need to store it once 
                        per customer.
                        If we need the customer information, we can obtain it from the customers table, by their 
                        customer_id. And, if we need the information for a subscription, all of its information is 
                        stored in the subscriptions table. We only need the customer_id and subscription_id in the 
                        orders table, and we can obtain their information from their respective tables.</li>
                    </ul>
                    <li>A <strong>database key</strong> is a column or group of columns in a table 
                    that uniquely identifies a row in a table.</li>
                    <ul>
                        <li><strong>Primary keys: </strong>Each of these tables has a column that uniquely identifies each row of that table:
                        <strong>order_id</strong> for orders; <strong>subscription_id</strong> for subscriptions;
                        <strong>customer_id</strong> for customers. These special columns are called <strong>primary 
                        keys</strong>. Sometimes, none of the columns in a table can uniquely identify a record. When 
                        this happens, we can designate multiple columns in a table to serve as the primary key,
                        also known as a <strong>composite primary key.</strong> Primary keys have a few requirements:</li>
                        <ul>       
                            <li>None of the values can be NULL.</li>
                            <li>Each value must be unique (i.e., you can’t have two customers with the same customer_id in the customers table).</li>
                            <li>A table can not have more than one primary key column.</li>
                        </ul>
                        <pre>
                            <code>
                //Composite primary key
                CREATE TABLE popular_recipes (
                    recipe_id varchar(20),
                    ingredient_id varchar(20),
                    downloaded integer,
                    PRIMARY KEY (recipe_id, ingredient_id)
                );
                            </code>
                        </pre>
                        <li><strong>Foreign keys: </strong>When the primary key for one table appears in a different 
                        table, it is called a foreign key.
                        The most common types of joins will be joining a foreign key from one table with the primary 
                        key from another table. Generally, the primary key will just be called <i>id</i>. 
                        Foreign keys will have more descriptive names.
                        To designate a foreign key on a single column in PostgreSQL, we use the <strong>REFERENCES</strong> keyword.</li>
                        <pre>
                            <code>
                CREATE TABLE person (
                    id integer PRIMARY KEY,
                    name varchar(20),
                    age integer
                );
                
                CREATE TABLE email (
                    email varchar(20) PRIMARY KEY,
                    person_id integer REFERENCES person(id),
                    storage integer,
                    price money
                );
                            </code>
                        </pre>
                    </ul>
                    <li><strong>Database Relationship</strong></li>
                    <ul>
                        <li><strong>One-to-one relationship: </strong> A row of table A is associated with exactly 
                        one row of table B and vice-versa. 
                        Use a foreign key to the referenced table.
                        To enforce a strictly one-to-one relationship in PostgreSQL, we need another keyword, UNIQUE. 
                        By appending this keyword and adding repeated rows, it will throw an error.
                        </li>
                        <pre>
                            <code>
                                CREATE TABLE driver (
                                    license_id char(20) PRIMARY KEY,
                                    name varchar(20),
                                    address varchar(100),
                                    date_of_birth date
                                );      
                                 
                                CREATE TABLE license (
                                    id integer PRIMARY KEY,
                                    state_issued varchar(20),
                                    date_issued date,
                                    date_expired  date,
                                    license_id char(20) REFERENCES driver(license_id) UNIQUE
                                ); 
                            </code>
                        </pre>
                        <li><strong>One-to-Many Relationship: </strong>
                        Analogous to a parent-child relationship where a parent can have multiple children, a parent table will house 
                        a primary key and the child table will house both primary and foreign keys. The foreign key binds the child 
                        table to the parent table. A one-to-many relationship exists when one row in a table links to many rows in another table.
                        Use a foreign key on the many side of the relationship linking back to the "one" side:</li>
                        <li><strong>Many-to-Many Relationship: </strong>
                        Many-to-many relationship can be broken into two one-to-many relationships.
                        To implement a many-to-many relationship in a relational database, we would create a third 
                        cross-reference table also known as a <strong>join table</strong>. It will have these two constraints:
                        <u>foreign keys</u> referencing the primary keys of the two member tables.
                        a <u>composite primary key</u> made up of the two foreign keys.
                        </li>
                    </ul>
                    <hr/>
                    <ul>
                        <li><strong>Joining: </strong>If we just look at the orders table, we can’t really tell 
                        what’s happened in each order. However, if we refer to the other tables, we can get a 
                        complete picture.</li> 
                        <ul>
                            <li>E.g: Related to order_id, we find a customer_id, 
                            that has a customer_name stored in the customer table;</li>
                            <li>E.g: Within order_id, we find the related subscritpion_id. Inside the 
                            subscription table we reach the description from that subscription_id.</li>
                        </ul>
                        <li><strong>JOIN:</strong> Combining tables manually is time-consuming. SQL gives 
                        us an easy sequence to join tables: JOIN.
                        When we perform a simple JOIN (often called an inner join) 
                        our result only includes rows that match our ON condition.
                        if we want to combine two tables and keep un-matched rows,
                        we use <strong>LEFT JOIN</strong>. A left join will keep all rows from the first table, 
                        regardless of whether there is a matching row in the second table,
                        but will omit the un-matched row from the second table.</li>
                        <pre>
                            <code>
                SELECT * 
                FROM orders
                JOIN customers
                    ON orders.customer_id = customers.customer_id;


                //if we only wanted to select orders table's 
                    order_id column and customers table's 
                    customer_name column:

                SELECT orders.order_id,
                    customers.customer_name
                FROM orders
                JOIN customers
                    ON orders.customer_id = customers.customer_id;

                //JOIN Multiple
                SELECT 
                    AVG(people.weight), 
                    teams.name, 
                    batting.yearid 
                FROM people 
                INNER JOIN batting 
                    ON people.playerid = batting.playerid
                INNER JOIN teams
                    ON batting.team_id = teams.id
                GROUP BY 
                    teams.name,
                    batting.yearid
                ORDER BY
                    AVG(people.weight) 
                    DESC;

                //LEFT JOIN
                SELECT *
                FROM table1
                LEFT JOIN table2
                    ON table1.c2 = table2.c2;
                            </code>
                        </pre>
                        <ul>
                            <li>The first line selects all columns from our combined table. If we only want to select 
                            certain columns, we can specify which ones we want.</li>
                            <li>The second line specifies the first table that we want to look in, orders</li>
                            <li>The third line uses JOIN to say that we want to combine information from 
                            orders with customers.</li>
                            <li>The fourth line tells us how to combine the two tables. We want to match orders 
                            table’s customer_id column with customers table’s customer_id column.</li>
                        </ul>
                        <li><strong>CROSS JOIN: </strong>Sometimes, we just want to combine all rows of one table with all rows of another table.
                        A more common usage of CROSS JOIN is when we need to compare each row of a table to a list of values.
                        For instance, if we had a table of shirts and a table of pants, we might want to know all the possible combinations to create different outfits. 
                        Our code might look like this:</li>
                        <pre>
                            <code>
                SELECT shirts.shirt_color, pants.pants_color
                FROM shirts
                CROSS JOIN pants;
                            </code>
                        </pre>
                        <ul>
                            <li>The first two lines select the columns shirt_color and pants_color.</li>
                            <li>The third line pulls data from the table shirts.</li>
                            <li>The fourth line performs a CROSS JOIN with pants.</li>
                        </ul>
                        <li><strong>UNION</strong> operator allows us to stack one dataset on top of the other. 
                        SQL has strict rules for appending data:
                        Tables must have the same number of columns.
                        The columns must have the same data types in the same order as the first table.
                        Duplicate rows will be excluded. If, however, you want to include duplicates, certain versions 
                        of SQL provides the UNION ALL operator.</li>
                        <pre>
                            <code>
                SELECT *
                FROM table1
                UNION
                SELECT *
                FROM table2;
                            </code>
                        </pre>
                        <li>Often times, we want to combine two tables, but one of the tables is the result of another calculation.
                        The <strong>WITH</strong> statement allows us to perform a separate query (such as aggregating customer’s subscriptions)
                        previous_results is the alias that we will use to reference any columns from the query inside of the WITH clause.
                        We can then go on to do whatever we want with this temporary table (such as join the temporary table with another table)
                        Essentially, we are putting a whole first query inside the parentheses () and giving it a name. After that, we can use 
                        this name as if it’s a table and write a new query using the first query.
                        You can use WITH for more than one nested query using commas after the WITH.</li>
                        <pre>
                            <code>
                WITH previous_results AS (
                    SELECT ...
                    ...
                    ...
                    ...
                )
                SELECT *
                FROM previous_results
                JOIN customers
                ON _____ = _____;
                            </code>
                        </pre>
                        <li><strong>Associating Tables: </strong>
                        We have a person table and an email table, where a person can have many email addresses, but 
                        an email address can only belong to one person. To implement this type of relationship, we 
                        need to apply a constraint on the email table by adding another column to it and designating 
                        it to associate with the person table.

                        Let’s say we have a hobby table as well and populate it with all kinds of hobbies. If we try 
                        to query both the hobby and person tables, how do we know for sure that a hobby is tied to a 
                        particular person? There is nothing in the person table that links it to a hobby.

                        To associate a hobby with a person, we need to relate the person table to the hobby table 
                        with the type of relationship they have. Can a person have only one hobby or multiple hobbies?
                        Can a hobby apply to only one person or can it be shared by multiple people?</li>
                    </ul>
                    <hr/>
                </div>
                <hr/>
                <li><strong>Database Trigger: </strong>
                Is procedural code that is automatically executed in response to certain events on a particular 
                table or view in a database. The trigger is mostly used for maintaining the integrity of the information 
                on the database. When you want something to happen every time someone makes a specific change to a table 
                or view, a trigger is placed on that table or view. That trigger will call a function when the conditions 
                for the trigger are met - triggers run in alphabetic order from their names. Adding a trigger saves people from forgetting to do that action, and ensures consistent rules are applied.
                Triggers are very customizable. You have control over when they get called, when they run, along with what 
                happens when they are called. There are two common options: BEFORE and AFTER.</li>
                <p class="center"><strong>Database Trigger:</strong></p>
                <button id="showCode51" onclick="showCode('displayCode51', 'showCode51')">Display</button>
                <div id="displayCode51">
                    <button onclick="closeCode('displayCode51', 'showCode51')">Close</button>
                    <li><strong>BEFORE</strong> calls your trigger before the query that fired the trigger runs.</li>
                    <li><strong>AFTER</strong> occurs once the query finishes its work.
                    This is quite useful for logging purposes, such as inserting into an audit table 
                    to track who did a change and when.</li>
                    <pre>
                        <code>
            //Newer versions of Postgre
                may use EXECUTE FUNCTION instead.
            CREATE TRIGGER < trigger_name >
                BEFORE UPDATE ON < table_name >
                FOR EACH ROW
                EXECUTE PROCEDURE< function >;
                        </code>
                    </pre>
                    <li><strong>FOR EACH ROW:</strong> The trigger will fire and call the function for every row that is 
                    impacted by the related query - therefore is called once for every row modified.
                    The other option is to have it set to FOR EACH STATEMENT.</li> 
                    <li><strong>FOR EACH STATEMENT: </strong> 
                    calls the function in the trigger once for each query, not for each record -
                    executes once for the entire operation (0 modified rows would still trigger this).</li>
                    <li>You can use a WHEN clause to filter when a trigger calls its related function.
                    You can use NEW and OLD to get records from the table before and after the query. Logically, INSERT 
                    can not refer to OLD (nothing existed before the insert) and DELETE can not refer to NEW (nothing 
                    exists after the delete).</li>
                    <pre>
                        <code>
                            CREATE TRIGGER < trigger_name >
                                BEFORE UPDATE ON < table_name >
                                FOR EACH ROW
                                WHEN (NEW.< column_name > < 13)
                                EXECUTE PROCEDURE < procedure_name >();
                        </code>
                    </pre>
                    <li><strong>DROP TRIGGER</strong> removes a trigger.</li>
                    <pre>
                        <code>    
        DROP TRIGGER < trigger_name > 
            ON < table_name >;</li>
                        </code>
                    </pre>
                    <li>To find what triggers exists, you can use <strong>information_schema.triggers</strong></li>
                    <pre>
                        <code>
        SELECT * FROM information_schema.triggers;
                        </code>
                    </pre>
                </div>
                <hr/>
                <li><strong>Designing</strong> Relational Databases</li>
                <ul>
                    <li><strong>Database Schema: </strong>Like an architectural blueprint, a database schema is documentation that helps its audience 
                    such as a database designer, administrator and other users interact with a database. It gives 
                    an overview of the purpose of the database along with the data that makes up the database, 
                    how the data is organized into tables, how the tables are internally structured and how they 
                    relate to one another. 
                    An <strong>Entity Relationship Diagram</strong>, or ERD, is a method of diagramming a database with a little more 
                    description put into it to allow a designer to better understand the database and the relationships 
                    between the tables - more info <a href="https://www.lucidchart.com/pages/er-diagrams#section_5" target="_blank">here</a>.</li>
                </ul>
                <p class="center"><strong>How to design:</strong></p>
                <button id="showCode52" onclick="showCode('displayCode52', 'showCode52')">Display</button>
                <div id="displayCode52">
                    <button onclick="closeCode('displayCode52', 'showCode52')">Close</button>
                    <li>When designing a database schema consider the following steps:</li>
                    <ul>
                        <li><strong>Define the purpose</strong> of your database</li>
                        <li><strong>Find the information</strong> that make up the database</li>
                        <li><strong>Organize</strong> your information into <strong>tables</strong></li>
                        <li><strong>Structure</strong> your tables into columns of information</li>
                        <li><strong>Avoid redundant data</strong> that leads to inaccuracy and waste in space</li>
                        <li><strong>Identify the relationships</strong> between your tables and implement them.</li>
                    </ul>
                    <li><strong>Three Tier Architecture:</strong> When discussing a new application or program that will be built, the number of tiers an 
                    application will need is going to likely be discussed. A tier is used to help separate the 
                    different processes that will be used within an application. This can be through the use of 
                    different tech stacks or by simply dividing into separate teams for each tier. These tiers are 
                    easier to understand after viewing a few examples which will be seen later in the article.
                    The three tiers are: </li> 
                    <ul>
                        <li><strong>Presentation tier: </strong>
                        This tier is the one most people will be familiar with as it represents items such as 
                        the user interface or GUI. It represents how the user will interact with the application.
                        This tier consists mostly of markup languages including HTML, JavaScript, and CSS,
                        This is because this tier is mainly for presenting and gathering information from the user, 
                        and less about processing the data in this tier.</li>
                        <li><strong>Data tier: </strong>
                        This is the tier that stores all of the data. Data at this level is not manipulated and is 
                        strictly for storage. This is usually just a database to store the data on. The data tier can 
                        only interact with the application tier, and is unable to communicate directly to the 
                        presentation tier. This is because of the fact that the data tier is strictly for storage and 
                        not manipulation. The data tier of applications is usually a database, meaning that services 
                        like SQL, MongoDB, and PostgreSQL are used to create the database and assist with querying later.
                        However, any querying done to the database is not considered to be a part of the data tier and is 
                        instead a part of the application tier.</li>
                        <li><strong>Application tier: </strong>
                        This is where the bulk of the application will go. This tier will deal with processing data 
                        gathered from the presentation tier and modifies the data within the data tier. It acts like a 
                        bridge connecting the two other tiers.  
                        For example, the application tier represents the process performed when you first opened an website's article. 
                        The data for a article is grabbed from the data tier and then converted into a form you 
                        can see in the presentation tier. The middle work between the two tiers is all done in the 
                        application tier.
                        Most of the work performed inside of the application tier will be done in programming languages 
                        such as Java, Python, Perl, and other popular programming languages. This is because they are 
                        best at manipulating the data into a number of different forms.</li>
                    </ul>
                    <li>An application can have as many tiers as wanted. 
                    Two tiered can hold only presentation and data tiers (it can be used for very simplistic websites).
                    More than three tiers can be used (but as more tiers are added though, it can become harder to maintain the project 
                    and can even slow it down due to all of the tiers the project has to manage).
                    A three tiered application is a nice middle ground for building a project. It allows for complex 
                    applications without slowing down the application. Through the use of a presentation tier, 
                    application tier, and data tier, full projects can be built and managed with different teams. 
                    The different tiers also help allow for improved scalability for when an application grows and is 
                    easier to manage than higher tiered application.</li>
                    <li><strong>Free online database design tools:</strong></li>
                    <ul>
                        <li><a href="https://dbdiagram.io/home" target="_blank">DbDiagram.io</a> is simple tool to 
                        draw ER diagrams by just writing code, designed for developers and data analysts.</li>
                        <li><a href="https://sqldbm.com/home" target="_blank">SQLDBM</a> is a SQL Database Modeler</li>
                        <li><a href="https://www.dbdesigner.net/" target="_blank">DB Designer</a> is a online database schema design and modeling tool</li>
                        <li><a href="https://www.lucidchart.com/pages/" target="_blank">Lucidchart</a> 
                        is the intelligent diagramming application that brings teams together to make better 
                        decisions and build the future.</li>
                    </ul>
                    <li><strong>More info: </strong></li>
                    <ul>
                        <li>Video information database-design <a href="https://www.youtube.com/watch?v=h0j0QN2b57M&list=PL_c9BZzLwBRK0Pc28IdvPQizD2mJlgoID&index=2" target="_blank">here</a></li>
                    </ul>
                    <li><strong>Users table: </strong>The columns that are usually put in a users table 
                    depend on the specific requirements of the Application
                    Some applications may require additional columns, such as a user's role, account status,
                    or other information relevant to the application. Some common columns that are often 
                    included are:</li>
                    <ul>
                        <li><strong>id (primary key)</strong></li>
                        <li><strong>first_name</strong></li>
                        <li><strong>last_name</strong></li>
                        <li><strong>email</strong></li>
                        <li><strong>password (encrypted)</strong></li>
                        <li><strong>phone</strong></li>
                        <li><strong>address</strong></li>
                        <li><strong>city</strong></li>
                        <li><strong>state</strong></li>
                        <li><strong>zip_code</strong></li>
                        <li><strong>country</strong></li>
                        <li><strong>created_at</strong></li>
                        <li><strong>updated_at</strong></li>
                    </ul>
                    <li><strong>Orders table: </strong>An orders table typically contains the following columns:</li>
                    <ul>
                        <li><strong>order_id:</strong> a unique identifier for the order</li>
                        <li><strong>user_id:</strong> a reference to the user who placed the order</li>
                        <li><strong>order_date:</strong> the date and time when the order was placed</li>
                        <li><strong>order_status:</strong> the current status of the order (e.g. pending, fulfilled, cancelled)</li>
                        <li><strong>total_price:</strong> the total price of the order</li>
                        <li><strong>shipping_address:</strong> the shipping address associated with the order</li>
                        <li><strong>billing_address:</strong> the billing address associated with the order (if different from the shipping address)</li>
                        <li><strong>payment_method:</strong> the payment method used for the order (e.g. credit card, PayPal)</li>
                    </ul>
                    <li><strong>Items table: </strong> Additional columns may be added depending on the 
                    specific needs of the application. For example, if the application has a category or tags system, 
                    the items table may include a category_id or tags column to help with filtering 
                    and search. In a typical e-commerce application, an items table 
                    might include the following columns:</li>
                    <ul>
                        <li><strong>id:</strong> a unique identifier for each item</li>
                        <li><strong>name:</strong> the name of the item</li>
                        <li><strong>description:</strong> a description of the item</li>
                        <li><strong>price:</strong> the price of the item</li>
                        <li><strong>quantity:</strong> the number of the item in stock</li>
                        <li><strong>image_url:</strong> a URL for an image of the item</li>
                        <li><strong>created_at:</strong> the timestamp for when the item was added to the database</li>
                        <li><strong>updated_at:</strong> the timestamp for when the item was last updated in the database</li>
                    </ul>
                    <li><strong>orders_items table: </strong>An orders_items table is typically used as a 
                    many-to-many relationship between the orders and items tables.
                    These columns allow the orders_items table to represent the items included in each 
                    order, along with the quantity and price of each item.
                    It generally includes the following columns:</li>
                    <ul>
                        <li><strong>order_id:</strong> A foreign key that references the id column of the orders table.</li>
                        <li><strong>item_id:</strong> A foreign key that references the id column of the items table.</li>
                        <li><strong>quantity:</strong> The number of items of this type in the order.</li>
                        <li><strong>price:</strong> The price of the item at the time of purchase, which may be different from the current price.</li>
                        <li><strong>created_at:</strong> The date and time the item was added to the order.</li>
                        <li><strong>updated_at:</strong> The date and time the item was last updated.</li>
                    </ul>
                </div>
                <hr/>
                <li><strong>Database Permissions</strong></li>
                <ul>
                    <li>The postgres user (or any initial user) has the ability to create new databases, tables, 
                    users, etc. In PostgreSQL, the term for a user with these types of permissions is <strong>superuser</strong>. 
                    A superuser bypasses all permission checks that other users face before being allowed to perform 
                    an action. It's dangerous to let a user have access to everything, that's why we restrict their permission.</li>
                </ul>
                <p class="center"><strong>More about permissions:</strong></p>
                <button id="showCode53" onclick="showCode('displayCode53', 'showCode53')">Display</button>
                <div id="displayCode53">
                    <button onclick="closeCode('displayCode53', 'showCode53')">Close</button>
                    <li><strong>View list</strong></li>
                    <ul>
                        <li><strong>pg_catalog.pg_roles:</strong> A listing of all users in the database and a description
                        of what special permissions these users have.</li>
                        <li><strong>information_schema.table_privileges:</strong> Description of the permissions a user 
                        (grantee) has on a table. This table can be used to answer questions about who can SELECT, INSERT,
                        UPDATE, etc. values on a table.</li>
                    </ul>
                    <li><strong>Mimic Role: </strong>As a superuser, you can use <strong>SET ROLE</strong> to mimic the permissions of other users. 
                    For example, if a superuser runs <i>SET ROLE < test role ></i> and then attempts to perform an action 
                    that role couldn’t, they’d receive an error message indicating that they don’t have permission.
                    This behavior is identical to connecting to the database with that role from the start. 
                    As superuser, you can run <i>SET ROLE < superuser role ></i> to regain all superuser privileges.</li>
                    <pre>
                        <code>
                    //Check the name of the current user
                    SELECT current_user;

                    //information_schema.table_privileges
                    SELECT grantor, grantee, table_schema, table_name, privilege_type
                    FROM information_schema.table_privileges 
                    WHERE grantee = 'userB';
                        </code>
                    </pre>
                    <li><strong>CREATE ROLE: </strong>As a superuser, one of the permissions you have is the ability to create new roles. In PostgreSQL, 
                    roles can either be login roles or group roles. <strong>Login roles</strong> are used for most routine database 
                    activity. <strong>Group roles</strong> typically do not have the ability to login themselves, but can hold other 
                    roles as “members” and allow access to certain shared permissions.
                    List of permissions available for CREATE ROLE <a href="https://www.postgresql.org/docs/10/sql-createrole.html" target="_blank">here</a>.</li>
                    <pre>
                        <code>          
                //Create new role
                CREATE ROLE < name > WITH < list of permissions >;

                //Alter role
                ALTER ROLE miriam WITH CREATEDB
                        </code>
                    </pre>
                    <li><strong>Table level security: </strong><strong>GRANT</strong> and <strong>REVOKE</strong> are statements used to modify 
                    permissions at the schema and table level.
                    Every table or schema in a PostgreSQL database has an owner that can set the permissions on their 
                    tables. As a superuser or table or schema owner, you may use GRAND and REVOKE to achieve that.
                    To use a schema, a role must have a permission 
                    called <strong>USAGE</strong> - without USAGE a role cannot access tables within that schema. Other schema level 
                    permissions include <strong>CREATE</strong> and <strong>DROP</strong>, which allow the grantee the 
                    ability to create or remove tables in that schema respectively. 
                    To interact with a table, a role must have USAGE on the table’s schema. 
                    Additionally, a table owner must also grant <strong>SELECT</strong>, <strong>UPDATE</strong>, 
                    <strong>DELETE</strong>, <strong>INSERT</strong> etc. on a specific table 
                    to define how that role can interact with the table.
                    Let's examine what this looks like in practice. As the owner of the schema finance, perhaps you'd 
                    like to grant the ability to SELECT and UPDATE a table named finance.revenue to a user named analyst.
                    You could accomplish this with the following:</li>
                    <ul>
                        <li>First by <strong>granting USAGE</strong> on the schema. In this example, analyst is also granted the ability 
                        to CREATE new tables in the schema. <i>GRANT USAGE, CREATE ON SCHEMA finance TO analyst;</i></li>
                        <li>Then by <strong>granting</strong> the table <strong>specific permissions</strong>. 
                        <i>GRANT SELECT, UPDATE ON finance.revenue TO analyst;</i></li>
                        <li>Any GRANT statement can be reversed using quite similar syntax. First replacing GRANT with 
                        <strong>REVOKE</strong> and TO to FROM. For example, to revoke the ability to UPDATE given above, the owner of 
                        the table could use the following statement:
                        <i>REVOKE UPDATE ON finance.revenue FROM analyst;</i></li>
                        <li><strong>Default Permission: </strong>With it a superuser can set permissions to be updated 
                        automatically when new objects are created in a schema
                        (Default permissions can be used to set permissions at the database level as well).
                        The following statement would allow analyst to SELECT on all newly-created 
                        tables in finance immediately after another user has created them:</li>
                        <pre>
                            <code>
                        ALTER DEFAULT PRIVILEGES IN SCHEMA finance
                        GRANT SELECT ON TABLES TO analyst;
                            </code>
                        </pre>
                        <li><strong>Group Role: </strong>Alice, bob, and charlie can each be login roles, and they can 
                        also all be members of a group role called employees.
                        This is a useful feature for maintaining databases with many users, but only a few “types” of users.
                        One member can belong to more than one group role.
                        For security reasons, PostgreSQL disallows the inheritance of certain powerful permissions such
                        as LOGIN, SUPERUSER, CREATEDB, and CREATEROLE. There are several ways to create a new group role:</li>
                        <pre>
                            <code>
        // CREATE ROLE and the WITH ROLE 
            this automatically adds the listed names to the role
        CREATE ROLE marketing WITH NOLOGIN ROLE alice, bob;

        //CREATE ROLE and a GRANT statement
            grants all the permissions of the newly created 
            role to the listed names.
        CREATE ROLE finance WITH NOLOGIN;
        GRANT finance TO charlie;

        //You can also add users to group(s) 
            on creation by specifying 
        IN ROLE along with the CREATE ROLE statement
        CREATE ROLE fran WITH LOGIN IN ROLE employees, managers; 
                            </code>
                        </pre>
                        <li><strong>Column level security: </strong>PostgreSQL offers the ability to write GRANT statements that specify specific <strong>columns</strong> for a set 
                        of permissions to apply to. Consider the following example:</li>
                        <pre>
                            <code>
        GRANT SELECT (project_code, project_name, project_status) 
        ON projects to employees;

        //To display grant by column
        SELECT *
        FROM information_schema.column_privileges 
        WHERE grantee = 'manager';
                            </code>
                        </pre>
                        <li><strong>Row-level security (RLS): </strong>PostgreSQL feature  
                        that allows developers to define permissions on individual rows. To access (or modify) information from a 
                        table with RLS, a row-specific condition must be met. Information about RLS 
                        <a href="https://www.postgresql.org/docs/10/sql-createpolicy.html" target="_blank">here</a>.</li>
                        <pre>
                            <code>
                            //First, we create a policy using a CREATE POLICY statement.
                            CREATE POLICY emp_rls_policy ON accounts FOR SELECT 
                            TO sales USING (salesperson=current_user);

                            //Next, we need to enable RLS on the table the policy refers to.
                            ALTER TABLE accounts ENABLE ROW LEVEL SECURITY;
                            </code>
                        </pre>
                    </ul>
                </div>
                <hr/>
                <li><strong>ACID </strong>(Atomic, Consistent, Isolated, and Durable): These properties help ensure that all the data in a 
                transaction is complete, accurate, and has integrity. These properties also assist in recovering databases in case of a system 
                failure and allows for concurrent use of a database.
                Any single unit of work done to the database is defined as a <strong>transaction</strong> - these transactions can often be 
                made up of multiple different steps, and most of the time represent changes made to the database.</li>
                <ul>
                    <li><strong>ATOM: </strong>“all changes to data are performed as if they are a single operation. That is, all the changes are performed, or none 
                    of them are.” This means that we treat each transaction as a single operation. If a single task in the transaction fails, 
                    then the entire transaction will fail. For example, let’s look at the following transaction</li>
                    <li><strong>Consistent: </strong>“Data is in a consistent state when a transaction starts and when it ends.”
                    Therefore, the transaction follows the rules from the database. E.g:
                    Inside of a banking application, whenever money is transferred from one account to another, we need to make sure that the no money was lost or 
                    added to the transaction. To do this, we would add the funds from both accounts together and store that value, transfer the money, 
                    then add the account values and check the initial value to make sure both are equal. </li>
                    <li><strong>Isolated: </strong>When working with multiple transactions that could occur at once, it is important to ensure that when one transaction 
                    is reading or writing from a location in to a database, no other transaction is reading or writing from that same location. This process is 
                    called isolation and is defined by IBM as “The intermediate state of a transaction is invisible to other transactions. As a result, 
                    transaction that run concurrently appear to be serialized.”
                    For example, if we had one transaction changing a row in a table, and another transaction trying to read data from that same table, 
                    these two transaction would not be able to operate at the same time. Instead, these transaction would execute one at a time.
                    This does not mean that we cannot perform multiple transactions at once. We can still have multiple transactions happen, it’s just 
                    that no two transactions can read or write from the same location at the same time. Otherwise, we could encounter issues where a 
                    transaction could use old data or a transaction could overwrite new data with old data.</li>
                    <li><strong>Durable: </strong>“after a transaction successfully completes, changes to data persist and are not undone, even in the 
                    event of a system failure.” These failures include instances of service outages and crashes. Durability can be achieved through a 
                    number of methods including change logs that are referenced whenever the database is restarted for whatever reason.</li>
                </ul>
                <hr/>
                <li><strong>SQL Injections </strong>
                Is a common vulnerability affecting applications that use SQL as their database language. A hacker can use 
                their knowledge of the SQL language to cleverly construct text inputs that modify the backend SQL query to their liking. 
                They can force the application to output private data or respond in ways that provide intel. <i>Union-Based Injections</i>,
                <i>Error-Based Injections</i>, <i>Boolean-Based Injections</i>, <i>Time-Based Injections</i>, <i>Out-of-Band SQL Injections</i></li>
                <ul>
                    <li><strong>SQL Injection Prevention: </strong>
                    There are two main methods for preventing injection attacks: <strong>sanitization</strong> and
                    <strong>prepared statements</strong>.</li>
                    <ul>
                        <li>Sanitization is the process of removing dangerous characters from user input. When it comes to SQL injections, 
                        we would want to escape dangerous characters such as: <i>' ; \--</i>
                        These sorts of characters can allow attackers to extend queries to output more data from a database.
                        While this does provide a layer of protection, this method isn’t perfect. If a user finds a way to bypass your 
                        sanitization process, they can easily inject data into your system.
                        Additionally, depending on your query, removing certain characters may have no effect! Therefore, this shouldn’t 
                        be your only defense mechanism.</li>
                        <li>Prepared Statements
                        Writing prepared statements in backend code is a common, reliable, and secure solution against SQL injections. 
                        Prepared statements are nearly foolproof.
                        How does it work? We provide the database the query we want to execute in advance. First, the database processes our 
                        query. Then we pass in the parameters/user input. Any input, regardless of whether the content has SQL syntax, is then 
                        treated only as a parameter and will not be treated as SQL code.
                        In addition to providing added security, prepared statements also make queries far more efficient.
                        Here is an example of what a prepared statement looks like in PHP web application backend code:</li>
                        <pre>
                            <code>
                        $username= $_GET['user'];
                        $stmt = $conn->prepare("SELECT * FROM Users WHERE name = '?'");
                        $stmt->bind_param("s", $username);
                        $stmt->execute();
                            </code>
                        </pre>
                    </ul>
                </ul>
                <hr/>
                <li><strong>Indexes:</strong> An index is an organization of the data in a table to help with performance when searching 
                and filtering records.
                It's a data structure that helps to speed up database queries by allowing the database to
                quickly locate the rows.
                A table can have zero, one, or many indexes.
                Indexing allows you to organize your database structure in such a way that it makes finding specific records much faster.
                In small databases this is negligible, but as the datasets get larger this becomes more significant.
                Indexes speed up searching and filtering, however, they slow down insert, update, and delete statements.
                One thing to consider using or not is whether searching will occur often enough to make the advantages worth the time and effort.</li>
                <p class="center"><strong>More about Indexes:</strong></p>
                <button id="showCode54" onclick="showCode('displayCode54', 'showCode54')">Display</button>
                <div id="displayCode54">
                    <button onclick="closeCode('displayCode54', 'showCode54')">Close</button>
                    <li><strong>Seek VS Scan: </strong>
                    Different names are used in differente databases. SQL Server uses Seek and Scan, PostgreSQL uses Scan, 
                    Index Scan and Bitmap Heap Scan. There are two major ways that a database searches for rows in a table/view when you 
                    run any query. This isn’t limited to SELECT statements — this applies to every type of query that needs to find specific 
                    rows. For example, in a database of orders, an UPDATE query for orders over $10k would need to search for those records.</li>
                    <ul>
                        <li><strong>Scan:</strong> Searches through every record in a database table/view to find the records being asked for.</li>
                        <li><strong>Seek:</strong> Uses an index to find the specific records being asked for by jumping to their location and either grabbing the 
                        data or, if it is a reference, using it to get the information.</li>
                        <li>The DB server decides if it should use a seek or scan. This means that even if you write your query to take advantage
                        of a good index, the server might ignore this and run the query using a scan. But why would it do this? If you are 
                        examining over 50% - 70% of the records in the table then seeking no longer offers any advantage. If you are regularly 
                        skipping the benefits of your indexes, they might need to be reexamined to see if the costs outweigh the benefits.</li>
                    </ul>
                    <li>To see existing indexes:</li>
                    <pre>
                        <code>
                    SELECT *
                    FROM pg_Indexes
                    WHERE tablename = 'products';
                        </code>
                    </pre>
                    <li><strong>Binary Tree (B-Tree): </strong> By default, index divides the possible matching records in half, then half, 
                    then half, and so on until the specific match you 
                    are searching for is found. This is known as a Binary Tree, or B-Tree.
                    Let’s consider an example to expand on this concept. Say you had a sales department where you ranked your clients from 
                    number 1 to 100 in order of loyalty. If you wanted to search the database for your most loyal client, who would have a 
                    loyalty score of 100, you would have to search every record (the highest loyalty score could be anywhere in the data set).
                    If you created an index on loyality_score, you could now use the B-Tree structure to speed up that search. The search would 
                    divide all results in half, so in this case, the first check would be if the record you are searching for is greater than or 
                    less than 50.</li>
                    <li><strong>EXPLAIN ANALYZE: </strong>To get insight into how PostgreSQL breaks down your statements into runnable parts, we can investigate the query plan 
                    by adding EXPLAIN ANALYZE before your query. Rather than returning the results of the query, it will return information 
                    about the query. More info <a href="https://www.postgresql.org/docs/current/sql-explain.html" target="_blank">here</a></li>
                    <ul>
                        <li><strong>Seq Scan</strong> this means that the system is scanning every record to find the specific records 
                        you are looking for. 
                        <strong>Index</strong> means the server is taking advantage of an index to improve the speed of your search.</li>
                        <li><strong>Planning time</strong> is the amount of time the server spends deciding the best way to solve your query, 
                        should it use an index, or do a full scan of the table(s) for instance. The <strong>execution time</strong> is the amount of time the 
                        actual query takes to run after the server has decided on a plan of attack. You need to take both of these into 
                        consideration, and when examining your own indexes these are critical to understanding how effective your indexes are.</li>
                        <li>We can use the code below and compare two different queries, to analyze if is faster using an index or 
                        doing a full scan of the table(s).</li>
                    </ul>
                    <pre>
                        <code>
                EXPLAIN ANALYZE SELECT *
                FROM customers;
                        </code>
                    </pre>
                    <li><strong>CREATE INDEX:</strong> 
                    When an index is created on a column, the database creates a separate data structure that 
                    contains the values from that column along with pointers to the actual rows in the table that containthose values.
                    In the code below, the "customers_user_name_idx" index will contain the values from the "user_name" column of the "customers" 
                    table and pointers to the rows in the table that contain those values. This will allow the database to quickly find all 
                    rows in the "customers" table that match a specific user name, which can be especially helpful if there are a large number 
                    of rows in the table.
                    To summarize, this code is creating an index on the "user_name" column of the "customers" table to speed up queries that 
                    involve searching for rows based on the values in that column:</li>
                    <pre>
                        <code>
                //user_name = column
                CREATE INDEX customers_user_name_idx ON customers (user_name);


                CREATE INDEX < index_name > ON < table_name > (< column_name >);
                        </code>
                    </pre>
                    <li>Much like constraints, you can <strong>combine multiple columns</strong> together as a single index. 
                    When using multicolumn indexes, the search structure will be based on the values found in all of the columns.
                    For example, an index on First and Last Name might be a good idea if it is common to search by both together in 
                    your situation. Consider a table where the last names 'Smith' and 'Johnson' appear many times. Having another filter 
                    for the first name can help you find someone named 'Sarah Smith' much faster.
                    The index is built in the specific order listed at creation, so (last_name, first_name) is different from 
                    (first_name, last_name). Keep this in mind when you are building your indexes as the order will impact the efficiency 
                    of your searches. You can create a multicolumn index as well (also known as Composite or Compound).</li>
                    <pre>
                        <code>
                //multicolumn index (Composite or Compound)
                CREATE INDEX customers_last_name_first_name_idx ON customers (last_name, first_name);
                        </code>
                    </pre>
                    <li><strong>DROP </strong>index: <i>DROP INDEX IF EXISTS customers_city_idx;</i></li>
                    <li><strong>Cons of using Index: </strong>
                    <ul>
                        <li>When new data is added, the index will be reshaped to fit that new data into 
                        its organization. This means that when you write a single statement to modify the records, the server will have to modify 
                        every index that would be impacted by this change. If you are adding a large amount of data to an existing table, it may 
                        be better to drop the index, add the data, and then recreate the index rather than having to update the index on each 
                        insertion. Keep in mind that these drawbacks are for each index you have on your table. If you have multiple indexes
                        on a single table and you insert a record, you will need to update each index associated with the table. This can make 
                        indexes very costly. If you are doing a large amount of inserts/updates it might be worth considering removing indexes 
                        before doing the changes then putting the indexes back in once you are done.
                        Updates and deletes have similar drawbacks. When deleting a record that is associated with an index, it might be faster 
                        to find the record — by leveraging the index’s ability to search. However, once the record is found, removing or editing 
                        it will result in the same issue as inserting a new record. The index itself will need to be redone. Note that if you’re 
                        updating a non-indexed column, that update will be unaffected by the index. So if you are updating a non-indexed column 
                        while filtering by one with an index, an update statement can actually be faster with an index.</li>
                        <li>Another place where an index falls short of perfection is that indexes take up space. The index data structures 
                        can sometimes take up as much space as the table itself.
                        Given the speed advantages indexes can provide when used properly, you should not ignore them, but keep in mind this balance.
                        If you wanted to examine the size of a table products you would run:
                        <i>SELECT pg_size_pretty (pg_total_relation_size('products'));</i></li>
                        <li><strong>When to use index?:</strong>
                        In the real world, this often becomes a grey area and one that you might have to go back to after trying for a while.
                        You will want to look at what a table is used for and by who. As a very rough rule of thumb, think carefully about any
                        index on a table that gets regular Insert/Update/Delete. In contrast, a table that is fairly stable but is searched 
                        regularly might be a good candidate for an index.
                        There are some other conditions that can impact your search times you should be aware of when using an index.
                        The higher the percentage of a table you are returning the less useful an index becomes. If we’re only searching 
                        for 1 record in 1,000,000, an index could be incredibly useful. However, if we are searching for 900,000 out of that 
                        same 1,000,000 the advantages of an index become useless. At higher percentages, the query planner might completely 
                        ignore your index and do a full table scan, making your index only a burden on the system.
                        Along this same line, if you are combining filtering conditions be aware of what you will be searching on. AND 
                        statements are normally fine and the query planner will try to use an indexed field before non-indexed fields to 
                        cut down on the total number of records needed to be searched. OR on the other hand, can be very dangerous; even 
                        if you have a single non-indexed condition, if it’s in an OR, the system will still have to check every record in 
                        your table, making your index useless.</li>
                    </ul>
                    <hr/>
                    <li><strong>Partial Index: </strong>
                    A partial index allows for indexing on a subset of a table, allowing searches to be conducted on just this group of 
                    records in the table. 
                    Unlike a regular index that indexes all rows in a table, a partial index only indexes the rows that satisfy a specified
                    condition. This can be useful in situations where only a subset of rows in a table are frequently queried, or where the 
                    indexed columns have a high degree of selectivity (i.e., only a small number of distinct values).
                    If you would be searching an index of ~258 Thousand instead of 70+ Million,
                    this can be powerful toolset when working with massive databases.
                    It can be used conditioning calculations as well, speeding up even more.</li>
                    <pre>
                        <code>
                CREATE INDEX users_user_name_internal_idx ON users (user_name)
                WHERE email_address LIKE '%@wellsfargo.com';
                        </code>
                    </pre>
                    <ul>
                        <li><strong>ORDER BY: </strong>
                        If you are commonly ordering your data in a specific way on an indexed column, you can add ORDER BY to the 
                        index itself and PostgreSQL will store the data in your desired order. By doing this, the results that are returned 
                        to you will already be sorted. You won’t need a second step of sorting them, saving time on your query.
                        This could improve the speed.</li>
                        <pre>
                            <code>
                CREATE INDEX logins_date_time_idx ON logins (date_time DESC, user_name);
                            </code>
                        </pre>
                    </ul>
                    <li><strong>Primary Keys and Indexes: </strong>PostgreSQL automatically creates a unique index on any primary key you 
                    have in your tables. It will also do this for 
                    any column you define as having a unique constraint. A unique index, primary key, and unique constraint all reject any 
                    attempt to have two records in a table that would have the same value (multicolumns versions of these would reject any 
                    record where all the columns are equal).
                    The primary key index standard is to end in _pkey instead of _idx to identify it as a specific type of index. It is also 
                    the way the system names it when created automatically.</li>
                    <li>All indexes are either a <strong>clustered index</strong> or a <strong>non-clustered index</strong>. 
                    For now, let’s focus on the clustered index. A clustered index is often tied to the table’s primary key.</li>
                    <ul>
                        <li><strong>Cluster</strong> refers to a group of tables that are physically stored together on disk based on 
                        their relationships with each other.
                        In a clustered database, related data is stored together on disk, which can improve query performance by reducing 
                        the need for disk seeks and improving data locality. For example, a database might cluster a "customer" table with 
                        an "orders" table based on their relationship, so that the orders for each customer are stored together on disk.</li>
                        <li><strong>Non-Clustered</strong>You can create many indexes on a table, but only one can be a clustered index, so 
                        what about the rest? They are known as non-clustered indexes. Non-clustered indexes have records of the columns they 
                        are indexing and a pointer back to the actual data in the table. If you are searching for just the records in the 
                        non-clustered index, the system will simply seek for your query results and return them. When you search on a 
                        non-clustered index for more information than is in the indexed columns, there are two searches. The first to 
                        find the record in the index and another to find the record the pointer identifies. There are some things you 
                        can do, such as creating a multicolumn index, that in some cases can help cut down or eliminate the need for the 
                        look back to the main table in memory.
                        Previously we compared how a clustered index functions as a dictionary. You can think of all other indexes 
                        (non-clustered) more akin to an index in a book. The keywords you are looking for are organized (by type, 
                        alphabetically, by the number of appearances, etc) and can be found quickly. However, the index doesn’t contain
                        information beyond that. Instead, it contains a pointer (page number, paragraph number, etc) to where the rest of 
                        the data can be found. This is the same way non-clustered indexes in databases work. You have a key that is sorted 
                        and a pointer to where to find the rest of the data if needed.</li>
                        <li><strong>Index-Only Scans: </strong>
                        The lookup that a non-clustered index does back to the table after finding records has a cost.
                        If you include the information that is regularly looked for, even if it isn’t used in the filtering, 
                        as part of the index, a secondary search can be avoided.</li>
                        <li><strong>Combining Indexes: </strong>
                        Previously we went over multicolumn indexes as a way PostrgeSQL can speed searches on multicolumn filtering, 
                        but if you don’t have an appropriate single index for a query, the server can combine indexes together to speed 
                        the filter. Like anything automatically handled by a system, there are some things to keep in mind when using 
                        this convenience.</li>
                        <ul>
                            <li>A single multicolumn index is faster (if ordered well) than combining indexes.</li>
                            <li>A multicolumn index is less efficient than a single index in cases where a single index is needed.</li>
                            <li>You could create all of them, then the server will try to use the best one in each case, but if they 
                            are all not used relatively often/equally then this is a misuse of indexes.</li>
                        </ul>
                        <li>Take for example, searching for first_name and last_name in the customers table.</li>
                        <ul>
                            <li>If searches are most often for only one of the columns, that should be your index.</li>
                            <li>If searches are most often last_name and first_name then you should have a multicolumn index.</li>
                            <li>If the searches are frequent and evenly spread among; first_name alone, last_name alone, and the 
                            combination of the two, that is a situation where you would want to have all three indexes.</li>
                        </ul>
                    </ul>
                    <pre>
                        <code>      
                //To cluster your database table using an existing index
                CLUSTER products USING products_product_name_idx;

                //If you have already established what 
                    index should be clustered (recluster)
                CLUSTER products;


                //if you want to cluster every table in 
                    your database that has an identified index

                CLUSTER;
                        </code>
                    </pre>
                    <li><strong>Indexes Based On Expressions: </strong>
                    An index is not limited to just a column reference, it can use the result of a function or scalar expression computed 
                    from one or more columns.
                    For example, if you want to ensure the company_name in a manufactures table is unique, you can add the UNIQUE option 
                    to make a unique index constraint on the results on your index. Any duplicate will then be rejected. Using UNIQUE here 
                    tells the system that your index also needs to be a constraint and only allow one record in the system that matches the 
                    criteria for your index. In other words, by creating an index with UNIQUE the system will automatically create the 
                    constraint to match the logic in the index at the same time. Just like the creation of a constraint, if you try to 
                    create an index in this way where the data already in the table does not pass, the system will reject your creation and 
                    notify you of the issue.
                    Let’s look at our UNIQUE example a bit more. In PostgreSQL, 'ExampleCompany' is NOT the same thing as 'examplecompany' 
                    even though we would probably want to reject this as a duplicate. You can add a function on your index to convert all 
                    your company_name data to lower case by using LOWER. This ensures that 'ExampleCompany' would be considered the same as 
                    'examplecompany'. This combination of the UNIQUE constraint and the use of the function LOWER would look like the code below.
                    These special indexes compound the pros and cons of indexes. Because the results of the expression are stored in the 
                    index, it saves the search function from having to perform it on every row on future searches. However, every change 
                    in the table data that impacts the index means it has to do the expression again, making Inserts and Updates more 
                    expensive on these indexes than a basic index. Be especially thoughtful about when to use indexes that use functions 
                    or expressions.</li>
                    <pre>
                        <code>
                    CREATE UNIQUE INDEX unique_manufacture_company_name_idx 
                    ON manufacture(LOWER(company_name));
                        </code>
                    </pre>
                    <hr/>
                    <li><strong>CREATE TEMP TABLE: </strong>If you are searching the same set of records from a table/view more than once in 
                    a block of code, put the filtered rows into an object such as a temp table, table variable, or view depending on the 
                    situation. This will eliminate the need to have to search the table/view for the same set of records more than once.</li>
                </div>
                <hr/>
                <li><strong>Postgree database management: </strong>
                The space PostgreSQL uses on disk can grow in several ways. Some ways are easier to predict, for example, the 
                addition of new tables or the addition of more data to a table. However, there are some properties of the PostgreSQL 
                data storage system that cause disk usage to increase in non-intuitive ways.</li>
                <p class="center"><strong>More about database management:</strong></p>
                <button id="showCode55" onclick="showCode('displayCode55', 'showCode55')">Display</button>
                <div id="displayCode55">
                    <button onclick="closeCode('displayCode55', 'showCode55')">Close</button>
                    <li><strong>Understanding Object Size:</strong> In order to manage database disk utilization, you should first be able to measure 
                    disk utilization. As a database user, you can use the following functions to check the size of a relation in a database.</li>
                    <ul>
                        <li><strong>pg_total_relation_size</strong> will return the size of the table and all its indexes in bytes. These values are often in the 
                        millions or billions and thus hard to read. Because indexes are relations in their own right, you can also call 
                        pg_total_relation_size on a single index to get the size of the index.</li>
                        <li><strong>pg_table_size</strong> and <strong>pg_indexes_size</strong> return the size of the table’s data and table’s 
                        indexes in bytes. The sum of these two functions is equal to pg_total_relation_size</li>
                        <li><strong>pg_size_pretty</strong> can be used with the functions above to format a number in bytes as KB, MB, or GB.</li>
                    </ul>
                    <pre>
                        <code>
                    SELECT 
                    pg_size_pretty(pg_table_size('time_series')) as tbl_size, 
                    pg_size_pretty(pg_indexes_size('time_series')) as idx_size,
                    pg_size_pretty(pg_total_relation_size('time_series')) as total_size;
                        </code>
                    </pre>
                    <li><strong>Dead tuples:</strong> Each row in a PostgreSQL table is stored in a file on the disk of the host machine. When an UPDATE or DELETE is called, 
                    PostgreSQL doesn’t physically delete the content from the disk. Instead, the database engine marks those rows so that they 
                    aren’t returned in user queries. These rows are called <strong>dead tuples</strong>, and although they aren’t referenced in the current 
                    version of databases’ tables, they still occupy space on disk and can affect performance.
                    Unlike updates, deletes don’t add space to a table - however, a DELETE statement will create dead tuples and leave the 
                    size of the table unchanged (when it should change to less).</li>
                    <li><strong>VACUUM: </strong>There are also statements you can use that allow you to actively manage disk usage. 
                    In PostgreSQL there is an operation 
                    called VACUUM that can be used to manage storage space. Running VACUUM <i>< table name >;</i> will vacuum a specific table,
                    while a VACUUM statement without a table name will run on the entire database. 
                    VACUUM simply marks dead tuples and allows that space to be re-used by future updates.</li>
                    <ul>
                        <li><strong>Autovacuum: </strong>To ensure that vacuuming isn’t left completely to the database users, PostgreSQL has a feature called autovacuum
                        enabled on most databases by default. When using autovacuum, PostgreSQL periodically checks for tables that have had a 
                        large number of inserted, updated or deleted tuples that could be vacuumed to improve performance. When autovacuum is 
                        enabled and finds such a table, a <i>VACUUM ANALYZE</i> command is run - this statement is a combination of two separate 
                        operations.</li>
                        <li>You can <strong>monitor</strong> a lot of information, such as last vacuum, autovacuum, dead tuplets, just
                        by querying the table <i>pg_stat_all_tables</i> for vacuum and analyze statistics.</li>
                        <pre>
                            <code>
                SELECT relname, 
                    last_vacuum,
                    last_autovacuum, 
                    last_analyze
                FROM pg_stat_all_tables 
                WHERE relname = 'books';
                            </code>
                        </pre>
                        <li><strong>VACUUM FULL: </strong>Rewrites all the data from a table into a “new” location on disk and only copies the required data 
                        (excluding dead tuples). This allows PostgreSQL to fully clear the space the table occupied. One of the significant 
                        drawbacks from VACUUM FULL is that it’s a slow operation that blocks other operations on the table while it’s working. 
                        If you’ve got a large table, this could mean a VACUUM FULL operation might block other user’s or application’s queries. 
                        In a local setting, this may seem trivial, but for production databases, preventing reads and writes on a table for even 
                        a few seconds can have lasting effects. VACUUM FULL is quite a heavy operation that should be used sparingly. 
                        The best strategy when designing a database maintenance plan is to make sure that VACUUM runs frequently and 
                        autovacuum is enabled.</li>
                        <pre>
                            <code>
                    //This will minimize subsequent
                        effects of dead tuples
                    VACUUM mock.time_series;

                    VACUUM ANALYZE < table_name >;

                    VACUUM FULL < table_name >;
                            </code>
                        </pre>
                        <li><strong>TRUNCATE: </strong>Occasionally, you may need to remove all the rows, but retain the structure of a table.
                        TRUNCATE quickly removes all rows from a table. It has the same effect as an unqualified delete, but since 
                        PostgreSQL doesn’t scan through the table first, TRUNCATE runs much faster on large tables. Finally, TRUNCATE 
                        simultaneously reclaims disk space immediately, rather than requiring a subsequent VACUUM or VACCUM FULL operation.
                        <i>TRUNCATE < table_name ></i></li>
                    </ul>
                    <li>More Info:</li>
                    <ul>
                        <li><strong>Performance cheatsheet </strong><a href="https://severalnines.com/blog/performance-cheat-sheet-postgresql/" target="_blank">here</a>.</li>
                        <li><strong>Advanced Postgree performance </strong><a href="https://thoughtbot.com/blog/advanced-postgres-performance-tips" target="_blank">here</a>.</li>
                        <li><strong>Performance Tuning PostgreSQL </strong><a href="https://www.revsys.com/writings/postgresql-performance.html" target="_blank">here</a>.</li>
                    </ul>
                </div>
                <hr/>
                <h3>Integrating PostgreSQL to Node</h3>
                <li><strong>Node-Postgres</strong></li>
                <ul>
                    <li><strong>Node-Postgres </strong>documentation <a href="https://node-postgres.com/" target="_blank">here</a>.</li>
                    <li><strong>Project structure </strong>with node-postgres <a href="https://node-postgres.com/guides/project-structure" target="_blank">here</a>.</li>
                </ul>
                <li><strong>Articles</strong></li>
                <ul>
                    <li><strong>CRUD REST API</strong> with Node.js, Express, and PostgreSQL <a href="https://blog.logrocket.com/crud-rest-api-node-js-express-postgresql/#what-express" target="_blank">here</a>.</li>
                    <li><strong>Why not use OMR?</strong><a href="https://blog.logrocket.com/node-js-orms-why-shouldnt-use/" target="_blank"> here</a>.</li>
                    <li>The minimal <strong>Node.js with Babel Setup</strong><a href="https://www.robinwieruch.de/minimal-node-js-babel-setup/" target="_blank"> here</a>.</li>
                    <li><strong>Setup Express.js in Node.js</strong><a href="https://www.robinwieruch.de/node-js-express-tutorial/" target="_blank"> here</a>.</li>
                    <li>Create a <strong>REST API with Express.js in Node.js</strong><a href="https://www.robinwieruch.de/node-express-server-rest-api/" target="_blank"> here</a>.</li>
                    <li><strong>Setup PostgreSQL with Sequelize(ORM) in Express</strong><a href="https://www.robinwieruch.de/postgres-express-setup-tutorial/" target="_blank"> here</a>.</li>
                    <li>Creating a <strong>REST API</strong> with <strong>Express.js and PostgreSQL</strong><a href="https://www.robinwieruch.de/postgresql-express-node-rest-api/" target="_blank"> here</a>.</li>
                    <li><strong>Postgres Performance Heroku</strong><a href="https://devcenter.heroku.com/categories/postgres-performance" target="_blank"> here</a>.</li>
                </ul>
                <li><strong>Samples</strong></li>
                <ul>
                    <li><strong>Sample Databases 1</strong><a href="https://wiki.postgresql.org/wiki/Sample_Databases" target="_blank"> here</a>.</li>
                    <li><strong>PostgresDB Samples 2</strong><a href="https://github.com/morenoh149/postgresDBSamples" target="_blank"> here</a>.</li>
                    <li><strong>PostgreSQL Samples 3</strong> <a href="https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/" target="_blank"> here</a>.</li>
                </ul>
                <li><strong>Supabase </strong><a href="https://supabase.com/" target="_blank">here</a>.</li>
                <li><strong>Tools: </strong>Working directly with databases from your application isn’t always easy. Differences in the way data structures are 
                represented often leads to challenges. The difficulty in expressing subtleties about relationships between different 
                entities can also cause issues. To address this, many different tools have been created to help act as an interface 
                between the core application and the data layer.
                We’ll look at some of the differences that arise between three common approaches:</li>
                <ul>
                    <li><strong>Raw SQL</strong></li> 
                    <li><strong>Query builders</strong></li>
                    <li><strong>ORMs (object-relational mappers)</strong></li>
                </ul>
                <p class="center"><strong>Types of tools:</strong></p>
                <button id="showCode56" onclick="showCode('displayCode56', 'showCode56')">Display</button>
                <div id="displayCode56">
                    <button onclick="closeCode('displayCode56', 'showCode56')">Close</button>
                    <li><strong>Raw SQL: </strong>
                    Some applications interface directly with the database by writing and executing queries using the native language 
                    supported by the database engine. Often, a database driver is all that is needed to connect, authenticate, and 
                    communicate with the database instance.
                    Developers can send queries written in the database’s native language through the connection. In return, the database 
                    will provide the query results, also in one of its native formats. For many relational database, the querying language 
                    of choice is SQL.
                    <ul>
                        <li><u>Benefits: </u>Developers write and manage the database queries and handle the results explicitly.
                        While this can be a lot of additional work, it means that there are few surprises in terms of what the database is storing,
                        how it is representing your data, and how it will supply that data when it is retrieved later. The lack of abstraction 
                        means that there are fewer “moving parts” that can lead to uncertainty.</li>
                        <li><u>Drawbacks: </u>
                        When interacting with a database from an application using plain SQL, you must understand the underlying data structure 
                        in order to compose valid queries. You are completely responsible for translating between the data types and structures 
                        that your application employs and the constructions available within the database system.
                        Another thing to keep in mind when working with raw SQL is that it is entirely up to you to manage the safety of your 
                        input. This is especially true if you are storing data provided by external users, where specially crafted input could 
                        induce your database to exposing information you hadn’t intended to allow (SQL injection).
                        Working with native querying languages almost always means composing queries with regular strings. This can be a painful 
                        process in cases where you must escape input and concatenate strings together to create a valid query. Your database 
                        operations can become wrapped up in many layers of string manipulation that has a high potential to accidentally mangle data.</li>
                    </ul>
                    <li><strong>Query builders: </strong>
                    Offers a thin layer of abstraction that specifically targets some of the major 
                    pain points of working directly with database-native languages. SQL query builders almost function as a templating system 
                    for querying, allowing developers to walk the line between working directly with the database and adding additional layers 
                    of abstraction. They do this by formalizing querying patterns and providing methods or functions that add input sanitation and 
                    automatically escape items for easier integration into applications.
                    <ul>
                        <li><u>Benefits:</u> Because query builders use the same constructions (methods or functions) as the rest of your application, 
                        developers often find them easier to manage long term than raw database queries written as strings. It is simple to tell 
                        the difference between operators and data and it is easy to decompose queries into logical chunks that handle specific 
                        parts of a query.
                        Makes it easier for those familiar with the database to understand what an operation will do. This isn’t always the case 
                        when using greater 
                        levels of abstraction.
                        SQL query builders often support multiple data backends, abstracting some of the subtle differences in various 
                        relational databases, for instance. This allows you to use the same tools for projects that use different databases.</li>
                        <li><u>Drawbacks: </u>SQL query builders suffer from a few of the same disadvantages as native querying languages.
                        Query builders still require you to understand and account for the database’s structures 
                        and capabilities, this means that you must have a fairly good 
                        grasp of SQL in addition to the specific syntax and capabilities of the query builder itself.
                        Additionally, SQL query builders still require you to define how the data you retrieve relates to your application data. 
                        There is no automatic synchronization between your in-memory objects and those in the database.</li>
                    </ul>
                    <li><strong>ORMs (object-relational mappers): </strong>ORMs generally
                    aim for a more complete abstraction with the hope of integrating with the application data more fluidly.
                    Object-relational mappers, or ORMs, are pieces of software dedicated to translating between the data representations in 
                    relational databases and the representation in memory used with object-oriented programming (OOP). The ORM provides an 
                    object-oriented interface to data within the database, attempting to use familiar programming concepts and reduce the 
                    amount of boilerplate code necessary in order to speed up development.
                    Object-oriented programming tends to produce a lot of structures with significant state and relationships that must be 
                    accounted for. Some other programming paradigms are more explicit about where state is stored and how it is managed. 
                    For instance, purely functional languages don’t allow mutable state, so state is often an input for functions or objects 
                    that output a new state. This clean separation of data from actions, as well as the explicitness of state life cycles can 
                    help simplify the interaction with the database.
                    Different ORMs employ different strategies to map between application and database structures. The two major categories are the 
                    active record pattern and the data mapper pattern.
                    <u>Drawbacks: </u>Many of these 
                    advantages act as a double-edged sword. They can prevent you from understanding your databases and can make it challenging 
                    to debug, change paradigms, or increase performance.
                    Perhaps the most well-known problem of working with ORMs is <strong>object-relational impedance mismatch</strong>, a term used to describe 
                    the difficulty of translating between object-oriented programming and the relational paradigm used by relational databases.
                    The incompatibilities between the data models used by these two categories of technology means that additional, imperfect 
                    abstraction is necessary with every increase in complexity. Object-relational impedance mismatch has been called the Vietnam
                    of computer science.
                    <ul>               
                        <li><strong>Active record</strong> pattern attempts to encapsulate the database’s data within the structure of objects within your code. 
                        Objects contain methods to save, update, or delete from the database and changes to your objects are meant to be easily 
                        reflected in the database. In general, an active record object in your application represents a record within a database.
                        Active record implementations allow you to manage your database by creating and connecting classes and instances within 
                        your code. Since these generally map class instances directly to database records, it is easy to conceptualize what is in 
                        your database if you understand what objects are used in your code.
                        Unfortunately, this can also come with some major downsides. Applications tend to be very tightly coupled with the 
                        database, which can cause problems when trying to migrate to a new database or even when testing your code. Your code 
                        tends to rely on the database to fill in gaps that were offloaded from your objects. The “magic” translation between these 
                        two domains can also lead to performance problems as the system tries to seamlessly map complex objects to the underlying 
                        data structure.</li>
                        <li><strong>Data mapper</strong> pattern is the other common ORM pattern. Like the active record pattern, the data mapper 
                        attempts to act as an independent layer between your code and your database that mediates between the two. 
                        However, instead of trying to seamlessly integrate objects and database records, it focuses on trying to decouple and 
                        translate between them while letting each exist independently. This can help separate your business logic from 
                        database-related details that deal with mappings, representation, serialization, etc.
                        So rather than letting the ORM system figure out how to map between the objects and the database tables, the developer 
                        is responsible for explicitly mapping between the two. This can help avoid tight coupling and behind-the-scenes 
                        operations at the expense of significantly more work in figuring out appropriate mappings.</li>
                    </ul>
                </div>
                <hr/>
                <h3>Postgres Security</h3>
                <li>Set up <strong>host-based authentication</strong> to define who is allowed to connect to the server.</li>
                <li>Implemented a <strong>role management system</strong> that operates on the Principle of Least Privilege.</li>
                <li>Enforced <strong>secure authentication</strong> and <strong>dissuaded automated attacks.</strong></li>
                <hr/>
                <h3>Authentication and authorization in POSTGRES</h3>
                <li><strong>Host-based authentication</strong> is a type of authentication mechanism that verifies the 
                identity of a user based on the host or computer they are using to access a system. In this 
                type of authentication, the identity of the user is authenticated based on the identity of 
                the computer or host from which the user is trying to access the system. More
                in <a href="https://www.codecademy.com/learn/paths/full-stack-engineer-career-path/tracks/fscp-22-data-security/modules/wdcp-22-authentication-authorization-postgres/cheatsheet" target="_blank">here</a></li>
                <ul>
                    <li><strong><i>pg_hba.conf</i></strong> file (created within the project) allows you to specify 
                    rules for how Postgres should handle 
                    different connections. Rules can apply narrowly or broadly, depending on how precise 
                    the parameters are. In the pg_hba.conf file, all the entries follow the same basic format, 
                    with blank lines or lines beginning with a # symbol being ignored. The basic format of 
                    entries is:</li>
                    <pre>
                        <code>
                connection_type  db  user  address  auth_method  [auth_options]
                        </code>
                    </pre>
                </ul>
                <p class="center"><strong>Example:</strong></p>
                <button id="showCode68" onclick="showCode('displayCode68', 'showCode68')">Display</button>
                <div id="displayCode68">
                    <button onclick="closeCode('displayCode68', 'showCode68')">Close</button>
                    <li>Let’s <strong>build an entry</strong>. The entry we’ll be building will allow SSL connections 
                    to a database called db_example for members of the g_example group on the same network 
                    as the server and use sha-256 password authentication.</li>
                    <ul>
                        <li><strong>connection_type</strong> will be <strong>hostssl</strong>, which matches external connections that use SSL. host is like hostssl, but matches connections that don’t use SSL as well.
                        db will be db_example. The keyword all can be used to match all databases.</li>
                        <li><strong>user</strong> will be <strong>+g_example</strong>. The + matches users who are members of this group, rather 
                        than the group itself. If we were creating a rule for a specific user, we would omit 
                        the +. The keyword all can be used to match all users.</li>
                        <li><strong>address</strong> will be <strong>samenet</strong>, a shorthand for connections on the same subnet as the 
                        server. Specific IP addresses can be put here as well. The keyword all can be used 
                        to match any address.</li>
                        <li><strong>auth_method</strong> will be <strong>scram-sha-256</strong>. There are other options, including reject, 
                        which unconditionally rejects connections matching the rule.</li>
                        <li>We’ll leave auth-options blank.</li>
                    </ul>
                    <li>All together, it looks like:</li>
                    <pre>
                        <code>
            hostssl  db_example  +g_example  samenet  scram-sha-256
                        </code>
                    </pre>
                    <li>The owner, who has the username u_owner, wants to be able to access all the 
                    databases from their home computer. Implement a rule to allow connections from their 
                    IP address: 104.20.25.250 using sha-256 password authentication. Since this connection 
                    goes over the public internet, the connection needs to use SSL.</li>
                    <pre>
                        <code>
            hostssl  all  u_owner  104.20.25.250  scram-sha-256
                        </code>
                    </pre>
                    <li>Let’s implement a <strong>default-deny</strong> rule at the very bottom of pg_hba.conf, to ensure 
                    that all external connections we don’t specifically allow are blocked. This rule should 
                    match all types of external connections, for all databases, users, and addresses, and 
                    reject them.</li>
                    <pre>
                        <code>
            host  all  all  all  reject
                        </code>
                    </pre>
                </div>
            <li><strong>User and Role Management:</strong>
            To solve this, you decide to create a system that uses three types of roles: permissions, 
            groups, and users.
            Permissions will determine privileges based on tasks, such as reading and writing to a given 
            table. Groups will be collections of permissions, and represent a group of users.
            Users represent specific people or applications, and join groups based on what their job is.
            We’ll be using two main commands today: CREATE ROLE and GRANT. <strong>A video implementation</strong>
            <a href="https://www.youtube.com/watch?v=aniANzg0BSk" target="_blank">here</a>.</li>
            <ul>
                <li><strong>CREATE ROLE</strong> follows the format
                below. It has a variety of optional parameters such as SUPERUSER/NOSUPERUSER, but Postgres provides 
                sensible default values for these parameters, so we won’t need to specify them here. 
                (You should always do extra research when creating your own application.) 
                <strong><i>CREATE ROLE role_name;</i></strong></li>
                <li><strong>GRANT</strong> follows two formats. <strong><i>PERMISSION ON table TO role;</i></strong>
                is used for granting permissions; if we wanted to allow the p_example role to select on the example table, we would 
                use GRANT SELECT ON example TO p_example;.
                <strong><i>GRANT role TO other_role;</i></strong> is used to assign one role to another role; if we wanted to 
                give g_example all the permissions of p_example, we 
                would use GRANT p_example TO g_example;.</li>
            </ul>
            <hr/>
            <h3>Server Configuration</h3>
            <li>A configuration file called <strong><i>postgresql.conf</i></strong> (created within the project) it's needed in order to make some final tweaks to improve the overall security of the 
            Postgres server. Some of the changes will enforce secure authentication, while others will make it more difficult for an 
            attacker to target the server using automated tools. We’ll be changing three parameters in this exercise:</li>
            <ul>
                <li>The <strong>listen_addresses</strong> parameter controls what IP addresses are allowed to connect to the server. 
                An IP address that isn’t 
                allowed to connect won’t even be able to try to authenticate. Setting this to '*' allows connections from any address to 
                try and authenticate, but this is generally a bad idea!</li>
                <li>The <strong>port parameter</strong> is the port the Postgres server listens on. Port numbers 49152—65535 aren’t reserved by any 
                software, so a port in this range usually doesn’t conflict with any other software.</li>
                <li>The <strong>ssl parameter</strong> determines whether or not the server will support SSL connections. In a real environment,
                the server also needs to be provided with the appropriate certificate and key.</li>
            </ul>
        </div>
          <div class="styleGuide">
            <h2>NoSQL</h2>
            <ul>
                <li><strong>NoSQL: </strong>
                NoSQL keeps all the information in one place, in the form of key-values or documents.</li>
                <ul>
                    <li>Benefits:<strong>Scalability:</strong> NoSQL was designed with
                    scalability as a priority. NoSQL can be an excellent choice for massive datasets that need to be 
                    distributed across multiple servers and locations.
                    <strong>Flexibility:</strong> Unlike a relational database, NoSQL databases don’t require a schema. This means that 
                    NoSQL can handle unstructured or semi-structured data in different formats
                    <strong>Developer Experience:</strong> NoSQL requires less organization and thus lets developers focus more on using
                    the data than on figuring out how to store it.</li>
                    <li><strong></strong>Drawbacks:</strong>
                    <strong>Data Integrity:</strong> Relational databases are typically ACID compliant, ensuring high data integrity. 
                    NoSQL databases follow BASE principles (basic availability, soft state, and eventual consistency)
                    and can often sacrifice integrity for increased data distribution and availability. However, some 
                    NoSQL databases do offer ACID compliance.
                    <strong>Language Standardization:</strong> While some NoSQL databases do use the Structured Query Language (SQL), 
                    typically, each database uses its unique language to set up, manage, and query data.</li>
                </ul>
                <li><strong>Types of NoSQL</strong> Databases:</li>
                <ul>
                    <li><strong>key-value database</strong> consists of individual records organized via key-value pairs. In this model, 
                    keys and values can be any type of data, ranging from numbers to complex objects. However, keys 
                    must be unique. This means this type of database is best when data is attributed to a unique key, 
                    like an ID number. Ideally, the data is also simple, and we are looking to prioritize fast queries 
                    over fancy features. Amazon <a href="https://aws.amazon.com/pt/dynamodb/" target="_blank">DynamoDB</a> 
                    and <a href="https://redis.com/" target="_blank">Redis</a> are popular options for developers 
                    looking to work with key-value databases.</li>
                    <li><strong>document-based</strong> (also called document-oriented) database consists of data stored in hierarchical 
                    structures. Some supported document formats include JSON, BSON, XML, and YAML. The document-based 
                    model is considered an extension of the key-value database and provides querying capabilities not 
                    solely based on unique keys. Documents are considered very flexible and can evolve to fit an 
                    application’s needs. They can even model relationships!
                    <a href="https://www.mongodb.com/?utm_campaign=academia_partners&utm_source=codecademy&utm_medium=referral" target="_blank">MongoDB</a> is a popular option for developers looking to work with a document database.</li>
                    <li><strong>graph database</strong> stores data using a graph structure. In a graph structure, data is stored in 
                    individual nodes (also called vertices) and establishes relationships via edges (also called 
                    links or lines). The advantage of the relationships built using a graph database as opposed to 
                    a relational database is that they are much simpler to set up, manage, and query. For example, 
                    let’s say we wanted to build a recommendation engine for our e-commerce store. We could establish
                    relationships between similar items our customers searched for to create recommendations.
                    <a href="https://neo4j.com/" target="_blank">Neo4j</a> is a popular option for developers looking to work with a graph database.</li>
                    <li><strong>column-oriented</strong> NoSQL database stores data similar to a relational database. However, 
                    instead of storing data as rows, it is stored as columns. Column-oriented databases aim to 
                    provide faster read speeds by being able to quickly aggregate data for a specific column. 
                    Amazon’s <a href="https://aws.amazon.com/redshift/" target="_blank">Redshift</a> is a popular 
                    option for developers looking to work with a column-oriented database.</li>
                </ul>
                <p class="center"><strong>Example:</strong></p>
                <button id="showCode48" onclick="showCode('displayCode48', 'showCode48')">Display</button>
                <div id="displayCode48">
                    <button onclick="closeCode('displayCode48', 'showCode48')">Close</button>
                    <ul>
                    </ul>
                </div>
            </ul>
        </div>
    </body>
</html>